% Formato para un capítulo cualquiera

%Título del capítulo
\chapter{Introducción} 
\label{sec:intro}
 
Según expresa Soderblom en \cite{Soderblom10}, se pueden medir muchas de las propiedades físicas claves de las estrellas. La masa se puede determinar a partir de la física básica, o también se puede inferir a partir de su tipo espectral, particularmente para la secuencia principal. La composición de las estrellas, no es fácil de determinar pero, se puede seguir un proceso bien comprendido en el que se conocen sus limitaciones. Sin embargo, la edad, que es el tercer determinante clave del estado físico de una estrella, no se puede medir directamente, solo se puede estimar. Únicamente se tiene la edad precisa y exacta de una estrella, el Sol. Pero esta edad no ha sido revelada por la propia estrella, sino que, se consigue estimar gracias a la posibilidad de estudiar en un laboratorio la materia que compone el sistema solar, estudio que no se puede hacer para ninguna otra estrella.

En algunas ocasiones, es posible determinar las edades si se colocan ciertos eventos en la secuencia correcta y se es capaz de comprender la duración relativa de cada una de las fases. Pero, normalmente se necesita unir observaciones de objetos o sucesos independientes para alcanzar la comprensión de un proceso. A continuación, se añade una serie de ejemplos que remarcan la utilidad de conocer la edad de ciertos objetos y su colocación temporal respecto al resto de sucesos:
%TODO_DONE: no entiendo como encajan el párrafo anterior y esta enumeración de items. ¿Son aplicaciones?
\begin{itemize}
\item La formación y evolución de los discos protoplanetarios parece ocurrir en los primeros 100 Myr de la vida de una estrella, y los discos de escombros se forman más tarde. En la actualidad, apenas se puede limitar esta escala temporal con los métodos disponibles, y para comprender la física de los procesos implicados, es necesario observar las diferencias en los procesos de formación y conocer la escala temporal entre ellos, además del de las estrellas implicadas.
\item Se han descubierto muchos planetas gigantes gaseosos alrededor de estrellas de tipo solar cercanas. Para obtener una mejor comprensión de, por ejemplo, la dinámica de tales sistemas y la migración hacia el interior de los planetas, se requieren edades precisas.
\item Se podría comprender mejor el comportamiento y el futuro de nuestro Sol si pudiéramos crear una verdadera cohorte basada en la masa, la composición y la edad. En la actualidad, las comparaciones del Sol con otras estrellas a menudo se basan en las propiedades estelares, el proceso es autorreferencial.
\item Para comprender completamente la historia de formación, enriquecimiento y dinámica de la Galaxia, se necesita poder asignar edades a las estrellas individuales. Las estrellas de baja masa viven lo suficiente para estar presentes en todas las épocas de formación estelar, lo que las hace atractivas para estos fines.
\item La búsqueda de vida y cualquier comprensión obtenida al observar signos de vida más allá de nuestro sistema solar tiene una profunda necesidad de medir las edades estelares si se espera obtener información sobre la evolución biológica.
\end{itemize}

La comprensión completa de una gran variedad de fenómenos astrofísicos significa que, al menos, se conoce la secuencia correcta de eventos y sus correspondientes escalas de tiempos. Muchos de estos fenómenos están relacionados con estrellas individuales o conjuntos de estrellas cercanas, por lo que se necesitan formas confiables de llegar a las edades de estos objetos.

Partiendo de que la edad es la propiedad más difícil de obtener, ya que es la única que no se puede observar \emph{directamente} en ningún caso y debe inferirse utilizando diversos métodos, Soderblom presentó dos estudios que describen la mayoría de estas técnicas \cite{Soderblom15, Soderblom10}.

Dentro del grupo de aproximaciones para la datación estelar, una de las técnicas más prometedoras es la girocronología o datación de estrellas mediante su periodo de rotación. Las estrellas nacen con un rango de velocidades de rotación por diferentes razones físicas, ver \cite{Barnes03}. En este trabajo, Barnes introduce la rotación como la característica observable más fundamental de las estrellas, además de ser una de las que más precisión admiten en su medición. El trabajo de Barnes se enfoca en la interpretación de datos relativos al periodo rotacional. Las observaciones de las estrellas de cúmulos abiertos sugieren que las estrellas en rotación se encuentran principalmente en dos secuencias. Estas secuencias y el número de estrellas que las componen, evolucionan sistemáticamente con la edad de los cúmulos.
%TODO_DONE: isócronoas rotaciones crudas? toma ya, cudiado con lo que pones, porque hay que explicarlo, yo no entraría en tantos detalles

Para entender mejor el estudio de Barnes, es necesario explicar que las isócronas son curvas en el diagrama de Hertzsprung-Russell (HR) que representan una población de estrellas de la misma edad. El diagrama de Hertzsprung-Russell, por definición, es un gráfico de dispersión de estrellas que representa la magnitud absoluta de una estrella en luz visible frente a su tipo espectral.

El proceso llamado frenado magnético reduce la velocidad de rotación de la estrella con el tiempo \cite{Schatzman62}. Desde finales de los 60's \cite{Belcher76, Kawaler88, Mestel68, Mestel87, Weber67}, se sabe que el frenado rotacional, o ley de frenado, es una función del periodo rotacional. Es decir, cuanto mayor sea la rotación, mayor será el frenado. Por lo tanto, con el tiempo, todas las estrellas tienden a converger a una velocidad de rotación similar para una edad y masa determinadas. Este efecto fue demostrado empíricamente por primera vez por Skumanich \cite{Skumanich72}. La girocronología es la técnica de datación estelar que explota este hecho \cite{Barnes16, Soderblom15}. Tradicionalmente, la girocronología se ha aplicado ajustando una expresión lineal que contiene la edad estelar, su periodo de rotación y algunas aproximaciones de su masa. En trabajos recientes, Angus y otros \cite{Angus20} \cite{Angus19} han propuesto nuevas relaciones lineales para la girocronología combinadas con otras técnicas de datación, como el ajuste de isócronas o la cinemática estelar, en un marco bayesiano para una estimación de edad más precisa. 

En \cite{Angus19}, por ejemplo, se demuestra que la combinación de la girocronología con el ajuste de isócronas mejora la precisión de las estimaciones de edad para estrellas enanas FGK sobre un único ajuste de isócronas. Además, se determina que la incorporación de los periodos de rotación al modelo de evolución estelar que emplean, ayuda a mejorar la precisión del resto de parámetros estelares. Por otro lado, también se deduce que la incertidumbre y los valores atípicos de los periodos de rotación se traducen en estimaciones inexactas por parte de la girocronología. Como conclusiones generales: 1) la forma óptima de determinar la edad de las estrellas implica combinar todos los observables disponibles que estén relacionados con la edad, y 2) ya que la girocronología funciona bien para estrellas enanas FGK y el ajuste de isócronas funciona bien para subgigantes y estrellas calientes, la combinación de ambos métodos da como resultado edades consistentemente precisas.


%\section{Motivación}
%TODO_DONE: esto no es la motivación, es un resumen del trabajo, por lo que quito la sección.

Sin embargo, debido a la dificultad para recolectar muestras de datos que sean lo suficientemente grandes para alimentar modelos de aprendizaje automático y que sean lo suficientemente precisas, no se ha intentado abordar el problema de la estimación de la edad de las estrellas como un ejercicio de regresión utilizando técnicas de Inteligencia Artificial. En este trabajo, se explora esta novedosa perspectiva, y las principales contribuciones son las siguientes.

En primer lugar, se ha recopilado un conjunto de datos empleados para determinar edades estelares mediante girocronología. En general, el conocimiento aportado sobre la girocronología se basa principalmente en los cúmulos estelares, los únicos sistemas con una gran cantidad de estrellas y una determinación precisa de la edad. Para este trabajo se ha construido una muestra completa y precisa con estrellas provenientes de diversos cúmulos, pero también provenientes de la astrosismología \cite{Angus15, Metcalfe19, Saders16}. La aparición de la astrosismología como una herramienta eficaz para datar estrellas ha permitido añadir una gran cantidad de estrellas de campo a la muestra. Todas las estrellas tienen una temperatura efectiva precisa ($T_{\rm eff}$), metalicidad ([Fe/H]), logaritmo de la gravedad superficial ($\log$ g), luminosidad ($L$), masa ($M$), radio ($R$), edad y periodo de rotación ($P_{\rm rot}$). La Sección \ref{sec:data} detalla la construcción de la muestra de datos, analizando fortalezas y debilidades. Supone un reto cuando se quiere estimar las edades estelares utilizando la girocronología, principalmente porque aún no se comprende completamente la física y las dependencias físicas del fenómeno de frenado rotacional. Sin embargo, se cree que este es un problema interesante para que las técnicas de aprendizaje automático ofrezcan lo mejor de sí mismas.

En segundo lugar, se presenta por primera vez un estudio comparativo de modelos de regresión de Inteligencia Artificial de última generación utilizando el conjunto de datos comentado (para conocer en detalle los casos que forman el estudio comparativo, consultar la Sección \ref{sec:benchmark}). Se incluye en el análisis un conjunto heterogéneo y completo de enfoques, que cubren: kNN clásico y regresión lineal o bayesiana; modelos combinados (bosque aleatorio, staking); proceso gaussiano; y redes neuronales. Se proponen hasta tres \emph{benchmarks} diferentes, donde se comparan todos estos modelos para entender su precisión, robustez y capacidad de generalización.

En tercer lugar, se estudia el algoritmo MAML (Model Agnostic Meta Learning) para tratar de solucionar el problema de la estimación de edades estelares. Este algoritmo se denomina agnóstico del modelo, siendo compatible con cualquier modelo entrenado con descenso de gradiente, y se basa en el metaaprendizaje para conseguir la resolución de nuevas tareas usando un número muy reducido de muestras. Este algoritmo permitirá el uso de conjuntos de datos muy reducidos provenientes de futuros estudios y futuras misiones que aporten información de nuevas estrellas. El análisis detallado del algoritmo y su aplicación se encuentra en la Sección \ref{sec:metalearning}.

Finalmente, en la Sección \ref{sec:results}, se revelan los resultados de los experimentos llevados a cabo con los modelos clásicos, donde algunos modelos logran un MAE de $<0.5$ Gyr en estimación de edades estelares, lo que puede considerarse un avance significativo en el campo. Además, para fomentar una mayor investigación sobre el problema, se publica la muestra de datos, los códigos para reproducir los experimentos y todos los protocolos de evaluación diseñados. Por otro lado, en la Subsección \ref{sub:maml_result} se detallan los resultados obtenidos con el algoritmo MAML. Aquí se puede observar un valor de error cuadrático medio muy próximo a 0 para las configuraciones más complejas de la red neuronal principal del modelo.

%TODO_DONE: te falta contextualizar en la introducción la parte de meta-learning, tal y como has hecho con las anteriores técnicas.
 

\chapter{Trabajos relacionados} 
\label{sec:related_work}

\section{Girocronología}
El beneficio principal de la girocronología está relacionado con la facilidad para obtener las entradas de observación requeridas: representaciones fotométricas o espectroscópicas de la masa estelar y el periodo de rotación. Por otro lado, presenta una serie de incertidumbres que la convierten en una técnica de datación poco precisa, además de tener un rango de aplicación relativamente estrecho en términos de masa. En \cite{Barnes03} y \cite{Barnes07}, se publica por primera vez una ecuación empírica que permite estimar la edad estelar en función de su periodo de rotación y su índice de color. Esto puede considerarse como el origen de la girocronología como técnica práctica. Esta relación empírica ha sido revisada posteriormente, en \cite{MH}, \cite{Barnes10} y \cite{Angus15}, utilizando una muestra de datos astrosísmicos en la última de estas. 

Pero en la vida real no suele ser tan sencillo. El frenado rotacional está ligado a la existencia de un campo magnético estelar bipolar. El mejor candidato para la dinamo que genera este campo es una zona convectiva exterior bien desarrollada. Por lo tanto, solo las estrellas con masas inferiores al límite de Kraft \cite{Kraft67}, alrededor de 1.3 M, pueden reducir su velocidad de rotación con el tiempo, siguiendo las leyes de ruptura conocidas. Pero, \cite{Zorec12} mostró que las estrellas A (estrellas blancas de la secuencia principal) también tienen velocidades de rotación que evolucionan con el tiempo, esto puede deberse a que en estas estrellas también pueden encontrarse fuertes campos magnéticos, o al menos sus firmas \cite{Balona17}, y por lo tanto, por encima del límite de Kraft, el frenado rotacional puede seguir existiendo. En este rango de masas, por encima de 1.3 M, el mecanismo exacto de frenado es casi desconocido.

Para las estrellas jóvenes, la girocronología solo puede aplicarse a cúmulos de estrellas o grupos en movimiento \cite{Curtis19}. Para las estrellas individuales, la incertidumbre asociada solo permite una declaración general sobre si es o no es joven. Por otro lado, \cite{Saders16} encontró, comparando un conjunto de 21 estrellas datadas usando astrosismología con modelos de frenado rotacional \cite{Saders13}, que a partir de cierto valor del número de Rossby, el frenado rotacional parece detenerse y la velocidad rotacional permanece en un estado estacionario, lo que hace que la girocronología tradicional sea casi inútil. En cualquier caso, este cambio en el régimen del frenado rotacional aún está en debate, con trabajos que lo confirman \cite{Gordon21}, \cite{Kitchatinov17}, \cite{Metcalfe19}, \cite{Metcalfe17} y \cite{Saders19}, y algunos otros que concluyen que no se observa, especialmente en el caso de gemelos solares en términos de masa y metalicidad \cite{Barnes16} y \cite{Oliveira19}.

Para profundizar sobre las últimas conclusiones obtenidas en relación a los periodos de rotación se revisa la última de las publicaciones comentada en el párrafo anterior. En \cite{Gordon21}, se miden los periodos de rotación de más de 8000 estrellas K2 de secuencia principal. En este estudio se detecta la brecha en la distribución del periodo de rotación y se muestra que es poco probable que se trate de una peculiaridad, ya que aparece en todas las campañas de K2. Tras revisar diferentes explicaciones y argumentos sobre la brecha, se deduce que lo más probable es que la brecha resulte de un giro estancado en la secuencia de rotación rápida para estrellas de baja masa, seguido de una rápida evolución a través de la brecha hacia la secuencia de rotación lenta.


\section{Modelos de IA para datación estelar}
Se pueden encontrar pocos trabajos que aborden el problema de la estimación de edades estelares mediante Inteligencia Artificial \cite{stardate}, \cite{Angus19}, \cite{das2018} y \cite{sanders2018}. Sander y Das presentan en \cite{sanders2018} un catálogo con distancias, masas y edades de 3 millones de estrellas de la segunda publicación de datos de Gaia \cite{Gaia2018}. %TODO_DONE: Añade referencia a Gaia
Las edades se estiman siguiendo un ajuste bayesiano a la estructura estelar y los modelos de evolución, para caracterizar sus funciones de densidad de probabilidad. Angus y otros \cite{stardate}, \cite{Angus19} proponen una combinación de las relaciones lineales para girocronología con isócronas ajustadas bajo un marco de estimación bayesiano. Su enfoque utiliza un proceso de cadena de Markov Monte Carlo para inferir las edades. Es en \cite{sanders2018} donde se encuentra por primera vez una Red Neuronal Bayesiana aplicada al problema de estimación de la edad. Técnicamente, Sander y Das \cite{sanders2018} entrenan un perceptrón multicapa, con una sola capa oculta de 10 neuronas, para generar distribuciones posteriores predictivas para la masa, edad y distancia de las estrellas. De esta manera, su modelo puede reemplazar la dependencia de la técnica de las isócronas. 

Las diferencias de todos estos trabajos con las desarrolladas en este proyecto son las siguientes. Todos los modelos anteriores abordan el problema desde una perspectiva bayesiana, centrándose en las predicciones de distribuciones posteriores de las edades. En cambio, aquí se propone un problema de regresión puro, donde los modelos se enfrentan a la estimación de un valor particular para la edad y se evalúan en consecuencia. Además, por este motivo, la comparación directa con estos trabajos anteriores no es tarea fácil.

Además de los trabajos mencionados, como prueba de lo prometedor que supone la aplicación de técnicas de Inteligencia Artificial para la datación estelar, durante la fase final de este proyecto se han encontrado trabajos recientes en los que se aplica aprendizaje automático para la predicción de edades estelares. En \cite{2020AAS...23633104M}, se presenta un modelo formado por dos redes neuronales convolucionales en cascada. Este método de aprendizaje profundo utiliza Gaia DR2 y fotometría 2MASS para predecir las edades estelares de las estrellas previas a la secuencia principal. En \cite{Jadhav_2021}, se presenta un estudio de cúmulos abiertos utilizando un telescopio de imágenes ultravioleta a bordo del ASTROSAT y Gaia EDR3. En este trabajo se combinan parámetros astrométricos, fotométricos y sistemáticos para entrenar un algoritmo de aprendizaje automático junto con un modelo de mezcla gaussiana para la determinación de la pertenencia al cúmulo.


\chapter{Base de datos}
\label{sec:data}
En este capítulo detallamos la base de datos con edades estelares que va a ser utilizada para validar los modelos de IA para estimación de edad estelar.
En concreto se trata de una muestra de 1464 estrellas con edades precisas procedentes de la astrosismología o la pertenencia a cúmulos. La muestra astrosísmica consta de 312 entradas para las cuales se han inferido observables estelares fundamentales precisos (temperatura efectiva, logaritmo de la gravedad superficial, masa, radio, contenido estelar de hierro sobre hidrógeno) a partir de una combinación de observaciones fotométricas, espectroscópicas y astrosismología. La contribución más significativa proviene de \cite{Serenelli17}, con 224 entradas. Otras se obtuvieron de \cite{Ceillier16},\cite{Garcia14},\cite{Silva15} y \cite{Silva17}. %TODO_DONE es correcto

\begin{table}[H]
\centering
\centering
\scalebox{0.8}{
\begin{tabular}{ccl}  
\toprule
Característica    & Unidad & Descripción \\
\midrule
\texttt{id} & - & ID de la estrella \\
$T_\texttt{eff}$ & K & Temperatura estelar efectiva \\
$log$g & dex & Logaritmo de la gravedad superficial\\
$M$ & Masas Solares & Masa estelar\\
$R$ & Radios Solares & Radio estelar \\
${\rm [Fe/H]}$ & dex & Contenido de Hierro sobre Hidrógeno\\
$P_{\rm rot}$ & Días & Periodo de rotación estelar \\
Edad & Gyr & Edad estelar\\
\bottomrule
\end{tabular}
}
\caption{Características proporcionadas en la base de datos para cada estrella.}\label{table:data}
\end{table}

En términos de periodo de rotación, de las 312 entradas obtenidas de la astrosismología, se tomaron 293 periodos de \cite{Garcia14}. Los periodos restantes se tomaron de \cite{Ceillier16}, \cite{Mazeh15}, \cite{McQuillan13a}, \cite{McQuillan14}, \cite{Nielsen13} y \cite{Reinhold13}. García y otros \cite{Garcia14} analizaron la tasa de rotación de la superficie en el subconjunto de estrellas de tipo solar Kepler, estudiadas en \cite{Garcia14}. Los mismos métodos de análisis implementados en \cite{Garcia14} se adoptan en \cite{Ceillier16}. En \cite{Nielsen13}, por otro lado, Nielsen et al. calcularon un periodograma Lomb-Scargle (LS). Eligieron como periodo de rotación el valor mediano de todos los picos registrados de potencia máxima medidos en varios trimestres de los datos de Kepler. En \cite{Reinhold13} también se usa el periodograma LS, pero restringiendo el análisis exclusivamente a los datos de cadencia larga del tercer trimestre de Kepler.

Se complementa la muestra con estudios de cúmulos realizados por la misión Kepler/K2. Se recopilan un total de 1152 entradas tomadas de \cite{Barnes16}, \cite{Gonzalez16}, \cite{Meibom11}, \cite{Meibom15} y \cite{Rebull17}. En \cite{Barnes16} y \cite{Gonzalez16}, los autores estudiaron el antiguo cúmulo M67, analizando los datos de las curvas de luz Kepler/K2 Campaign 5. M67 es un objetivo interesante para la girocronología, ya que tiene aproximadamente la misma edad y comparte una composición química similar a la del Sol. M67 también es el grupo más antiguo de la muestra. Barner y otros \cite{Barnes16}, derivaron los periodos de rotación de superficie utilizando una combinación de cuatro métodos: minimización de la dispersión de fase, longitud mínima de la cuerda, método de detección de la señal del periodo bayesiano y función de autocorrelación. En \cite{Gonzalez16}, se utilizó el método de análisis de periodograma de Lomb-Scargle. La edad del cúmulo se estableció por \cite{Barnes16} y su concordancia con las edades derivadas de la cromosfera \cite{Giampapa06} y la isócrona \cite{Bellini10}. Meibom y otros en \cite{Meibom11} estudiaron NGC 6811 \cite{Janes13} y \cite{Meibom15}, y reportaron periodos para estrellas en NGC 6819 \cite{Jeffries13}. Estos dos grupos cierran la brecha de edad entre Praesepe y M67. Estos autores emplearon el método de periodograma LS para obtener los periodos de rotación. Además, para todos los periodos de rotación reportados, examinaron visualmente el periodograma y las curvas de luz, y también verificaron los periodos de forma independiente utilizando el algoritmo CLEAN. Se observó a Praesepe durante la Campaña 5 de Kepler/K2. En \cite{Rebull17}, los autores identificaron los periodos de rotación de superficie aplicando el periodograma Lomb-Scargle. Tomaron el periodo correspondiente al pico más fuerte del periodograma como periodo de rotación (con algunas excepciones). El estudio produjo periodos para más del 80\% de todas las curvas de luz de Praesepe. La estimación de la edad de este grupo ha sido objeto de cierto debate, con el valor más reciente establecido en $760 \pm 60$ Myr por \cite{Brandt15}.

Para trabajar con la mayor exactitud y precisión, se han completado la muestra de los cúmulos con masas y radios derivados con un modelo de Random Forest de aprendizaje automático del paquete R empiricalRelationsMR \cite{Moya18}.


La muestra es, por lo tanto, una mezcla de cuatro cúmulos con edades de 0.79, 1, 2.5 y 4.2 Gyr que reúnen un total de 1152 estrellas, con masas y radios estimados mediante aprendizaje automático y datos empíricos. Por otro lado, se tienen 312 estrellas con masas, radios y edades determinadas mediante astrosismología y periodos de rotación precisos. Finalmente, se han seleccionado aquellas estrellas FGK y de secuencia principal con periodos de rotación inferiores a 50 días. La razón de este filtrado es que la física detrás de la girocronología ocurre principalmente en estos tipos estelares y, por lo tanto, está limitada a un rango de masas de 0.7 a 2. Además, los periodos de rotación superiores a 50 días difícilmente pueden explicarse por la estructura estelar actual y los modelos de evolución.

Se van a apartar 32 estrellas no agrupadas (incluido el Sol) datadas utilizando astrosismología con fines de prueba. Por lo tanto, se trabaja con una muestra final formada por 397 estrellas en cúmulos más 240 estrellas estudiadas mediante astrosismología, es decir, un total de 637 estrellas.

Desafortunadamente, esta muestra exhibe dos sesgos importantes: 1) la muestra astrosísmica está sesgada hacia las estrellas masivas y ancianas; y 2) la muestra basada en cúmulos está cuantificada por edad y sesgada hacia edades más jóvenes. En los experimentos se muestra que, a pesar de los sesgos, las técnicas de aprendizaje automático pueden extraer información confiable del conjunto de datos para estimar edades estelares. Con el tiempo, especialmente con las misiones espaciales actuales y futuras, estos sesgos se irán mitigando progresivamente, con la consecuente mejora de las estimaciones.


\section{Entendiendo la base de datos}

En la Figura \ref{Fig:HR_select}, se muestra la posición en el diagrama de Hertzsprung-Russell de todas las estrellas MS (secuencia principal) seleccionadas. También se muestra cuáles son los miembros de un cúmulo y cuáles se han caracterizado mediante astrosismología. Aquí se puede ver que las estrellas astrosísmicas cubren la zona más masiva y/o evolucionada del diagrama HR, y las estrellas del cúmulo son más jóvenes y también cubren la región de baja masa.

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.9\linewidth]{Figuras/sampling_MS_astro_clust_embedded.pdf}
\end{center}
\caption{Diagrama HR mostrando la muestra MS.}
 \label{Fig:HR_select}
\end{figure}

La idea clásica de la girocronología consiste en estimar las edades estelares utilizando cualquier indicador de la masa estelar y el periodo rotacional estelar. Como se tiene una estimación de masa para toda la muestra de entrenamiento, se puede representar directamente $M$ vs. $P_{\rm rot}$ (Fig. \ref{Fig:M_rot}), evitando usar otros indicadores. En este gráfico, también se diferencian las estrellas astrosísmicas de los cúmulos. No hay diferencias claras entre ellos, excepto el sesgo ya mencionado de la muestra astrosísmica hacia estrellas más masivas. El límite de Kraft está claro alrededor de 1,2M$_\odot$.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.9\linewidth]{Figuras/M_Prot_embedded.pdf}
\end{center}
\caption{$M$ - $P_{\rm rot}$ para las estrellas elegidas.}
 \label{Fig:M_rot}
\end{figure}


Si se añade la información de la edad estelar a la gráfica $M$ vs. $P_{\rm rot}$, se obtiene la Figura \ref{Fig:M_Age_rot}. Aquí se puede observar que, con una gran dispersión, cuanto mayor es $P_{\rm rot}$, mayor es la edad. Es destacable que también es cierto para estrellas masivas, por encima del límite de Kraft. Es decir, incluso en ausencia de una envolvente convectiva exterior desarrollada, también se produce la reducción de la velocidad de rotación con el tiempo.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/M_Prot_Age_embedded.pdf}
\end{center}
\caption{$M$ - $P_{\rm rot}$ para las estrellas elegidas. La edad se muestra en escala de color.}
 \label{Fig:M_Age_rot}
\end{figure}

Si se representa la edad frente a su periodo de rotación, se obtiene la Figura \ref{Fig:Age_rot}. En general, se confirma que a mayor edad, mayor periodo de rotación, con una gran dispersión, principalmente para estrellas en cúmulos debido a la dependencia de masa del frenado de rotación. También se ha ajustado una regresión lineal a esta relación, diferenciando entre las estrellas astrosísmicas y los cúmulos. Aquí se puede observar uno de los sesgos de la muestra. Estas relaciones lineales tienen la misma tendencia pero apenas son diferentes para cada subgrupo. En cualquier caso, la dispersión es realmente grande y no se puede asegurar que estas regresiones se puedan utilizar para estimar la edad. Esta es la razón por la que se pasa a métodos de análisis basados en Inteligencia Artificial para generar modelos adecuados para estimaciones de edades estelares.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Age_Prot_embedded.pdf}
\end{center}
\caption{$Edad$ - $P_{\rm rot}$ para las estrellas elegidas. Las estrellas astrosísmicas y de cúmulos se muestran en colores diferentes. También se representa la regresión lineal obtenida usando estos dos grupos.}
 \label{Fig:Age_rot}
\end{figure}


\chapter{Modelos de Inteligencia Artificial para datación estelar}
\label{chap:AI_4_date} 
%TODO_DONE: introduce/explica el contenido de todo este capítulo.
Este apartado contiene, en primer lugar, la descripción de los modelos clásicos de IA que forman parte del análisis comparativo, detallando cuales son los hiperparámetros que se optimizan para llegar a los resultados obtenidos. En segundo lugar, se detallan los 3 \emph{benchmarks} que se plantean para evaluar el rendimiento de todos los modelos, incluyendo gráficas que ilustran las edades que componen los conjuntos de entrenamiento y prueba. Por último, se detallan los resultados obtenidos en cada uno de los 3 \emph{benchmarks}, adjuntando diferentes gráficas que ilustran el rendimiento de todos los modelos en los escenarios de interpolación, control y el escenario base.

\section{Modelos}
\label{sec:models}

\textbf{Linear Regressor} {} Primero se entrena un modelo de datación de estrellas asumiendo que la edad es combinación lineal de las características proporcionadas en la muestra de datos. Sea $\hat{a}$ el valor de la edad predecida, entonces
\begin{equation}
\hat{a}(\vb{w}, \vb{x}) = w_0 + w_1 x_1 + ... + w_D x_D \; ,
\end{equation}
donde $\vb{x}$ y $\vb{w}$ codifican el vector de características de entrada y el coeficiente del regresor lineal, respectivamente. Se sigue el enfoque de mínimos cuadrados para el aprendizaje del modelo, resolviendo un problema de la forma: $\min_{\vb{w}} || \vb{X} \vb{w} - \vb{a}||_2^2$. $\vb{X}$. $\vb{X}$ es una matriz que contiene todos los vectores de entrenamiento y $\vb{a}$ es el vector de edades. 

Durante la fase de aprendizaje del modelo, se lleva a cabo una optimización de su hiperparámetro interno \emph{normalize} a través de un proceso de \emph{grid search} con validación cruzada. De forma predeterminada se encuentra desactivado, pero al activarlo, los regresores X se normalizan antes de la regresión restando la media y dividiendo por la norma l2.

\vspace{0.5cm}

\textbf{Bayesian Regression} {} Se implementa un regresor Bayesian Ridge para estimar un modelo probabilístico del problema de datación estelar con la forma:
\begin{equation}
p(a|\vb{X},\vb{w},\alpha) = \mathcal{N}(a|\vb{X} \vb{w},\alpha)\; ,
\end{equation}
donde se asume la edad salida $a$ como una distribución gaussiana sobre $\vb{X}\vb{w}$. $\alpha$ se estima directamente a partir de los datos que se tratan como una variable aleatoria. El parámetro de regularización se ajusta a los datos disponibles, introduciendo sobre los hiperparámetros del modelo, \ie $\vb{w}$, el siguiente gaussiano esférico $p(\vb{w}|\lambda) =
\mathcal{N}(\vb{w}|0,\lambda^{-1}\mathbf{I}_{D})$.

Para este regresor, se optimiza con validación cruzada el hiperparámetro asociado al número máximo de iteraciones, que tomará los valores 100, 200, 300, 400, 500.

\vspace{0.5cm}

\textbf{Decision Tree Regressor} {} Se usa un modelo de árbol de decisión \cite{Breiman1984}. %TODO_DONE: da detalles sobre lo que son los árboles de decisión. Tienes información en la propia página de sckit
Los árboles de decisión son un método de aprendizaje no paramétrico cuyo objetivo es crear un modelo capaz de predecir una variable objetivo siguiendo reglas de decisión simples inferidas de las características de los datos. Destacan por ser un método fácil de entender e implementar, pero, también por convertirse en modelos demasiado complejos con dificultad para generalizar.
Durante el aprendizaje, el modelo optimiza sus hiperparámetros internos a través de un proceso de \emph{grid search} con validación cruzada. Específicamente, se ajustan: la estrategia par elegir la división en cada nodo del árbol (mejor o aleatorio); el número mínimo de muestras requeridas para estar en un nodo hoja (5, 10, 50, 100); y la función para medir la calidad de la división (error cuadrático medio, error cuadrático medio con la puntuación de mejora de Friedman para posibles divisiones, error medio absoluto con reducción de la desviación de Poisson para encontrar divisiones). 

\vspace{0.5cm}

\textbf{Random Forest Regressor} {} Este modelo de regresión se implementa siguiendo el trabajo de Breiman \cite{Breiman2001}, donde los árboles de decisión se construyen a partir de las muestras de datos extraídas con reemplazo del conjunto de entrenamiento. Los árboles de decisión individuales suelen tender al sobreajuste. Los bosques aleatorios lograr reducir la varianza del modelo al combinar diversos árboles, aunque suele ser a costa de un ligero sesgo. La aleatoriedad inyectada en los bosques produce árboles de decisión con errores de predicción desacoplados. Al tomarse el promedio de las predicciones, algunos errores pueden anularse. %TODO_DONE: lo mismo añade detalles sobre random forest
De nuevo se usa un proceso de \emph{grid search} más validación cruzada para ajustar los siguientes hiperparámetros: número de árboles (5, 10, 50, 100); número mínimo de muestras requeridas para estar en un nodo hoja (5, 10, 50, 100); y la función para medir la calidad de la división (error cuadrático medio o error medio absoluto).

\vspace{0.5cm}
de
\textbf{Support Vector Regression} {} Las máquinas de vectores soporte son un modelo que representa los puntos de la muestra en el espacio, separando una clase de otra mediante hiperplanos, tratando de mantener la máxima distancia posible con las muestras. El objetivo de este modelo consiste en encontrar el hiperplano que separe ambas clases de forma óptima. Una de las grandes ventajas de este modelo es que presenta una alta efectividad en espacios de gran dimensión, además, permite permite especificar diferentes funciones de kernel para la función de decisión. En el estudio se incluye este modelo de regresión, basado en la implementación de LibSVM para regresión, \cite{LIBSVM}, siguiendo la aproximación $\epsilon$-SVR. %TODO_DONE: lo mismo añade detalles
Se emplea el kernel RBF, y se realiza una un \emph{grid search} con validación cruzada para ajustar el parámetro $C$ (1, 10, 100, 1000).

\vspace{0.5cm}

\textbf{Gaussian Process} {} Se entrena un regresor de proceso gaussiano \cite{Rasmussen2006}, donde se supone que la media es constante y cero. Los procesos gaussianos son un método genérico de aprendizaje supervisado. Algunas de sus ventajas principales se basan en que su predicción es probabilística, lo que le permite calcular intervalos de confianza y reajustar la predicción en base a estos. Además, al igual que las máquinas de vectores soporte, también permite especificar diferentes kernels. Este método también presenta algunas desventajas, como su pérdida de eficiencia en espacios de gran dimensión.  %TODO_DONE: lo mismo añade detalles
Se usa un kernel que es la suma de los siguientes tres kernels:
%TODO_DONE: mete cada Kernel en un item, junto a su fórmula y explicación, para que quede más ordenado.
\begin{itemize}
\item RBF: $k(\vb{x}_i, \vb{x}_j) = \text{exp}\left(- \frac{d(\vb{x}_i, \vb{x}_j)^2}{2l^2} \right)$, donde $d(\cdot, \cdot)$ es la distancia euclídea y $l$ es el parámetro de escala de longitud. Este es un kernel estacionario, las siglas RBF provienen de \emph{Radial-basis function} aunque también se conoce como kernel exponencial al cuadrado.
\item Producto escalar: $k(\vb{x}_i, \vb{x}_j) = \sigma_0 ^ 2 + \vb{x}_i \cdot \vb{x}_j$. Es un kernel no estacionario que se obtiene de la regresión lineal usando $N(0, 1)$ sobre los coeficientes de $x_i (i = 1, \ldots, N)$ y $N(0, \sigma_0^2)$ para el sesgo.
\item White kernel: $k(x_i, x_j) = noise\_level \text{ if } x_i == x_j \text{ else } 0$. La aplicación clave del White kernel es formar parte de un kernel suma donde se explica el ruido de la señal como independiente e idénticamente distribuido siguiendo una función normal.
\end{itemize}
%TODO_DONE: no entiendo la traducción que has hecho de lo que pusimos en el paper. Revisa lo que quieres decir.

\vspace{0.5cm}

\textbf{k-Nearest Neighbors} {} También se incluye en la comparativa un regresor kNN. El principio de este modelo consiste en encontrar el número predefinido de muestras de entrenamiento más cercanas en distancia al nuevo punto y predecir la etiqueta a partir de ellas. A pesar de su simplicidad, este modelo ha tenido éxito en gran cantidad de problemas de clasificación y regresión.  %TODO_DONE: lo mismo añade detalles
Para este problema, se ajusta el parámetro k (1, 5, 10, 15, 20, 50) y el tipo de función de ponderación que se usa para escalar la contribución de cada vecino. Se exploran dos tipos de funciones de ponderación: a) uniforme, donde todos los puntos en cada vecindario se ponderan por igual; y b) distancia, que pondera los puntos por la inversa de su distancia a un punto de consulta.

\vspace{0.5cm}

\textbf{Neural Network} {} La arquitectura implementada se muestra en la figura \ref{fig:neural_network}. Ésta consiste en un perceptrón multicapa. El modelo incluye una capa de entrada, un conjunto de 3 capas ocultas \emph{fully-connected} con 50 unidades en cada una, y la capa de salida encargada de la regresión de las edades de las estrellas. Cada unidad oculta va seguida de una función de activación ReLU. Se usa como función de pérdidas el error cuadrático medio, $Loss(\hat{a},a,W) = \frac{1}{2}||\hat{a} - a ||_2^2 + \frac{\alpha}{2} ||W||_2^2$, donde $W$ codifica los pesos de la red, y $\alpha$ es el parámetro de regularización. La técnica de propagación inversa \cite{LeCun2012} se utiliza para el aprendizaje del modelo con el optimizador SDG~\cite{sgd}. Durante el aprendizaje, se fija $\alpha=0.01$, y se usa una política de tasa de aprendizaje adaptativa, comenzando con un valor $0.1$.

\vspace{0.5cm}

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.6\linewidth]{Figuras/nnet.pdf}
\end{center}
\caption{Arquitectura de la red neuronal implementada. Se han usado 3 capas ocultas, con 50 unidades en cada una seguida de una ReLU. La salida no tiene función de activación, para realizar directamente la estimación de la edad.}
\label{fig:neural_network}
\end{figure}

\textbf{Stacking} {} Finalmente, se emplea un método de ensamblado en aprendizaje automático conocido como generalización apilada o stacking \cite{Wolpert1992}. El modelo consiste en apilar la salida de los estimadores individuales y usar un regresor para calcular la predicción final. Esto permite tener en cuenta el potencial de cada estimador individual, utilizando su salida como entrada de un estimador final.  %TODO_DONE: lo mismo añade detalles
Por tanto, las predicciones de cada regresor individual (nivel 0) se apilan y se introducen en un estimador final (nivel 1), que calcula la predicción de la edad. Para este proyecto, en el nivel 0, se integran: Neural Network y Gaussian Process. Para la última capa (nivel 1), se incorpora un Linear Regressor. Durante el entrenamiento, y para generalizar y evitar sobreajuste, el estimador de nivel 1 se entrena con muestras externas (tomadas del conjunto de entrenamiento), siguiendo una metodología de validación cruzada.

\section{Escenarios de evaluación}
\label{sec:benchmark}

La base de datos, detallada en la Sección \ref{sec:data}, ofrece más de 600 estrellas, con edades precisas, donde se propone construir los siguientes escenarios de evaluación.

\vspace{0.5cm}

\textbf{Problema de datación estelar (Benchmark A)} {} En esta configuración, se propone evaluar los diferentes modelos de regresión siguiendo un esquema clásico de división de datos de entrenamiento/prueba. A partir de la distribución de la muestra de datos, se define un conjunto de entrenamiento y un conjunto de pruebas, donde el  80 \% y el 20 \% de las estrellas se han incluido al azar, respectivamente. En la Figura \ref{fig:benchA_train} se detalla la distribución de las estrellas en el conjunto de entrenamiento y en la Figura \ref{fig:benchA_test} la del conjunto de prueba. Tras la observación de ambas figuras se puede concluir: 1) los límites de edad son similares para ambos conjuntos y 2) predominan las estrellas pertenecientes a los cúmulos de 0.7 y 4.2 Gyr. 

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_training.pdf}
\end{center}
\caption{Benchmark A: Distribución de las estrellas que forman el subconjunto de entrenamiento.}
 \label{fig:benchA_train}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_test.pdf}
\end{center}
\caption{Benchmark A: Distribución de las estrellas que forman el subconjunto de prueba.}
 \label{fig:benchA_test}
\end{figure}


\textbf{Capacidad de generalización (Benchmark B)} {} En primer lugar, se proporciona un estudio de generalización para los modelos, que consiste en realizar el entrenamiento  sobre estrellas \emph{jóvenes}, para posteriormente evalúa su rendimiento en estrellas \emph{ancianas}. Este escenario, denominado Benchmark B1, es interesante para evaluar la capacidad de los modelos de Inteligencia Artificial para trabajar con estrellas cuyo rango está fuera del conjunto de entrenamiento. Los rangos de edad de entrenamiento y prueba son $[0.4,4.2]$ y $[4.2,13.8]$ Gyr, respectivamente. En la Figura \ref{fig:benchB1_train} se detalla la distribución de las estrellas en el conjunto de entrenamiento y en la Figura \ref{fig:benchB1_test} la del conjunto de prueba.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_training.pdf}
\end{center}
\caption{Benchmark B1: Distribución de las estrellas que forman el subconjunto de entrenamiento.}
 \label{fig:benchB1_train}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_test.pdf}
\end{center}
\caption{Benchmark B1: Distribución de las estrellas que forman el subconjunto de prueba.}
 \label{fig:benchB1_test}
\end{figure}

También se propone un segundo escenario para evaluar la capacidad de generalización de los modelos cuando se entrenan solo con estrellas pertenecientes a cúmulos. En la práctica, la girocronología se utiliza para datar estrellas individuales que pueden tener cualquier edad. Las estrellas de los cúmulos suelen estar datadas gracias a su pertenencia a los propios cúmulos. En este Benchmark B2, se propone el entrenamiento de los modelos utilizando únicamente estrellas pertenecientes a cúmulos. El resto de estrellas se incluyen en el conjunto de prueba. En total, este escenario recoge 397 y 240 muestras para entrenamiento y prueba, respectivamente.

En la Figura \ref{fig:benchB2_train} se detalla la distribución de las estrellas que forman el conjunto de entrenamiento, aquí se observa la concentración de estas en las 4 edades principales de cada uno de los cúmulos (0.79, 1, 2.5 y 4.2 Gyr).
Por otro lado, la Figura \ref{fig:benchB2_test} detalla la distribución del conjunto de prueba. En esta gráfica se observa una mayor dispersión sobre el rango total de edades, aunque sigue apareciendo una mayor concentración de estrellas en la edad de 2.4 Gyr. %TODO_DONE_DONE: qué se observa? algo que destacar?

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_training.pdf}
\end{center}
\caption{Benchmark B2: Distribución de las estrellas que forman el subconjunto de entrenamiento.}
 \label{fig:benchB2_train}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_test.pdf}
\end{center}
\caption{Benchmark B2: Distribución de las estrellas que forman el subconjunto de prueba.}
 \label{fig:benchB2_test}
\end{figure}

\textbf{Regresión para datación estelar sobre una muestra de control (Benchmark C)} {} Aquí se propone examinar el rendimiento de todos los modelos sobre una muestra de datos de control compuesta por estrellas que no pertenecen a ningún cúmulo, y con una distribución de edades más realista/generalista. Específicamente, en este Benchmark C, se evalúan los modelos entrenados con toda la muestra de datos sobre un conjunto de $32$ estrellas nuevas, no pertenecientes a cúmulos, incluyendo el Sol. Este conjunto independiente de control se ha obtenido de las mismas fuentes basadas en astrosismología utilizadas para recopilar la información de la muestra descrita en la Sección \ref{sec:data}. Se han reservado 32 estrellas de estas fuentes, antes de construir la base de datos. El rango de edad de este conjunto va de 1,2 a 10,1 Gyr. Este rango se superpone con el rango de edad utilizado en la muestra de entrenamiento ($[0.4, 13.8]$ Gyr), e incluye algunas edades nuevas no observadas. Se presta especial atención a la precisión de los modelos para la estimación de la edad del Sol (4.6 Gyr). En la Figura \ref{fig:benchC_train} se detalla la distribución de las estrellas en el conjunto de entrenamiento y en la Figura \ref{fig:benchC_test} la del conjunto de prueba.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_training.pdf}
\end{center}
\caption{Benchmark C: Distribución de las estrellas que forman el subconjunto de entrenamiento.}
 \label{fig:benchC_train}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_test.pdf}
\end{center}
\caption{Benchmark C: Distribución de las estrellas que forman el subconjunto de prueba.}
 \label{fig:benchC_test}
\end{figure}


\section{Resultados}
\label{sec:results}
A continuación, se presenta la configuración experimental y se informa de los resultados obtenidos en la evaluación de los modelos detallados en la Sección \ref{sec:models}. Este \emph{benchmarking} se realiza a través de los 3 escenarios descritos: el efecto de los diferentes modelos (Benchmark A); la capacidad de generalización (Benchmark B); y el rendimiento sobre una muestra de control (Benchmark C).

\subsection{Configuración experimental}

\paragraph{Implementación} 
Para poder realizar una comparación entre modelos, se han creado todos en Python, usando la librería scikit-learn \cite{scikit-learn}. Se utilizan las siguientes siglas para identificar los modelos implementados: Neural Network (nnet), Linear Regressor (lr), Decision Tree Regressor (dtr), Random Forest Regressor (rf), Support Vector Regression (svm), Bayesian Regression (bayes), k-Nearest Neighbors (kNN), Gaussian Process (gp) y Stacking (stacking).

\paragraph{Métricas de evaluación}
La métrica de evaluación principal utilizada es el error medio absoluto, $MAE = \frac{\sum_{i=1}^{N}|a_i-\hat{a}_i|}{N}$, donde $a_i$ y $\hat{a}_i$, son la edad proporcionada por el conjunto de datos y la edad estimada por un modelo de regresión, respectivamente. Dado que el conjunto de datos proporciona información sobre la precisión de la edad de cada estrella, en forma de límites de error, también se propone utilizar como métrica de evaluación de la precisión el porcentaje de predicciones de la edad de las estrellas que se encuentran dentro del intervalo de confianza proporcionado por el propio conjunto de datos.

\paragraph{Gráficas}
Antes de abordar cada uno de los \emph{benchmarks}, es necesario introducir brevemente las gráficas que permiten profundizar en el rendimiento de los modelos. En primer lugar, se muestra un gráfico de barras que recoge un resumen con el MAE de cada uno de los modelos. A continuación y para cada uno de los modelos, se observan 3 gráficas diferentes. La primera de las gráficas permite observar las estimaciones que caen dentro del margen de error. La segunda gráfica muestra detalladamente la predicción, incluyendo el error obtenido para cada uno de los casos. La tercera gráfica muestra un histograma que recoge el MAE en función de la edad de las estrellas del conjunto de prueba.

\subsection{Benchmark A: Problema de datación estelar}

La Figura \ref{fig:benchA_models} muestra el rendimiento de todos los modelos, permitiendo la comparativa del MAE de cada modelo. En este escenario es interesante observar que se tienen 2 modelos, más su Stacking, que presentan los mejores resultado, estableciendo un margen de rendimiento con respecto a los demás. Son la Red Neuronal y el Proceso Gaussiano. Su Stacking reduce ligeramente el mejor MAE, de la Red Neuronal, de 0,405 a 0,400.

Analizando los 6 modelos restantes, se observa que, la mayoría de los modelos presentan dificultades en la estimación de la edad de las estrellas más viejas. También es relevante el resultado proporcionado por un modelo tan simple como un kNN (ver Figura \ref{fig:benchA_details_knn_1} y Figura \ref{fig:benchA_details_knn_2}), con un MAE de solo 0.53 Gyr. El éxito de este modelo se explica mediante los cúmulos que forman la base de datos, donde se encuentran muchos elementos concentrados en 2 valores de edad muy específicos, lo que permite que modelos como kNN hagan estimaciones muy precisas sobre las estrellas de prueba con estas edades. Este hecho se corrobora en la Tabla \ref{table:precisions}, donde se observa que la mejor precisión la logra el modelo kNN, seguido por la Red Neuronal. En general, a excepción de lr y bayes, todos los modelos ofrecen un MAE por debajo de 0.7 Gyr, lo que supone un gran avance en el campo de la datación estelar.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_models.pdf}
\end{center}
\caption{Benchmark A: Rendimiento de los modelos en función del MAE. En esta configuración, las dos mejores aproximaciones son Neural Network (nnet) y Gaussian Process (gp), y por lo tanto, su Stacking.}
 \label{fig:benchA_models}
\end{figure}

\paragraph{Stacking} 
A continuación, se muestran las 3 gráficas que detallan el rendimiento del modelo Stacking, el cual ha presentado el menor MAE en este benchmark, 0.400 Gyr. En la Figura \ref{fig:benchA_details_stacking_1} se observa que se tienen estimaciones dentro del margen de confianza para todo el espectro de edades, aunque, también se observa una acumulación de fallos en la estimación de las edades cercanas a 0.7 y 4.2 Gyr. En la Figura \ref{fig:benchA_details_stacking_2} se aprecia que los errores más pronunciados se dan para edades inferiores a 1, concretamente, las edades pertenecientes al cúmulo de 0.7 Gyr. Además, en la Figura \ref{fig:benchA_details_stacking_3} se observa una diferencia del error medio entre edades de 0.45 Gyr, lo que supone una diferencia relativamente alta.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_stacking_1.pdf}
\end{center}
\caption{Benchmark A: Rendimiento para el modelo Stacking.}
 \label{fig:benchA_details_stacking_1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_stacking_2.pdf}
\end{center}
\caption{Benchmark A: Predicción detallada para el modelo de Stacking. Se observa la edad real (en azul), la predicción de los modelos (en naranja), y el error correspondiente (en rojo).}
 \label{fig:benchA_details_stacking_2}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_A_stacking_3.pdf}
\end{center}
\caption{Benchmark A: MAE en función del rango de edad del conjunto de prueba.}
 \label{fig:benchA_details_stacking_3}
\end{figure}

En las Figuras \ref{fig:benchA_details_1_1}, \ref{fig:benchA_details_1_2}, \ref{fig:benchA_details_1_3} y \ref{fig:benchA_details_1_4} se adjuntan las gráficas que detallan el rendimiento de los modelos Neural Network, Gaussian Process, kNN y Random Forest. En sus correspondientes gráficas se puede apreciar:

\paragraph{Neural Network} 
La red neuronal es el segundo mejor modelo, después del stacking, con un MAE de 0.405 Gyr. Al igual que con el modelo del Stacking, en las gráficas de la red neuronal se aprecia cierta dificultad para colocar todas las estrellas los cúmulos de 0.7 y 4.2 Gyr dentro del margen de confianza. Por otro lado, el error medio entre edades varia desde 0.2 a 0.8 Gyr, aumentando la diferencia del modelo de Stacking.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Gaussian Process} 
El tercer mejor modelo es el Proceso Gaussiano, con un MAE de 0.453 Gyr. A diferencia de los dos modelos anteriores, aquí se empiezan a observar dificultades para estimar edades entre 0.4 y 4.2 Gyr, obteniendo un mayor número de puntos fuera del margen de confianza. Además, la segunda gráfica, relativa al error para cada edad, muestra errores de valor constante pero con mayor presencia a lo largo de todo el conjunto de edades. También destaca, en la tercera figura, la similitud que muestra el error medio para edades de hasta 7 Gyr, que es 4 veces menor que el error medio para las edades de más de 10 Gyr.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{kNN} 
Las gráficas del modelo kNN, el cual ha presentado una MAE de 0.532 Gyr, muestran una mayor dispersión de las estrellas estimadas, incluyendo menos estrellas dentro del intervalo de confianza. Por primera vez se observa una mala estimación para las edades más altas. Además, la figura de errores, muestra picos más pronunciados que los vistos hasta el momento, lo que indica una degradación en el rendimiento de los resultados obtenidos.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Random Forest} 
El último modelo de este bloque es el de Random Forest, con un MAE de 0.572 Gyr. En este caso se observa una dispersión relativamente controlada, respecto a lo visto anteriormente, pero se siguen presentando dificultades para estimas las edades de 0.7, 1 y 4.2 Gyr. En la segunda figura se observan errores de valor constante para todo el espectro de edades, aunque, el mayor error medio se sigue teniendo en las edades superiores a 10 Gyr.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

%Benchmark A
\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_nnet_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_nnet_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_nnet_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_nnet_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_nnet_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_nnet_3.pdf}}
\end{minipage}\par\medskip
\caption{Modelo Neural Network}
\label{fig:benchA_details_1_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_gp_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_gp_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_gp_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_gp_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_gp_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_gp_3.pdf}}
\end{minipage}\par\medskip
\caption{Modelo Gaussian Process}
\label{fig:benchA_details_1_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_knn_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_knn_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_knn_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_knn_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_knn_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_knn_3.pdf}}
\end{minipage}
\caption{Modelo k-Nearest Neighbor}
_\label{fig:benchA_details_1_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_rf_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_rf_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_rf_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_rf_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_rf_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_rf_3.pdf}}
\end{minipage}
\caption{Modelo Random Forest}
\label{fig:benchA_details_1_4}
\end{figure*}

En las Figuras \ref{fig:benchA_details_2_1}, \ref{fig:benchA_details_2_2}, \ref{fig:benchA_details_2_3} y \ref{fig:benchA_details_2_4} se adjuntan las gráficas que detallan el rendimiento de los modelos Support Vector Regression, Decision Tree Regressor, Linear Regressor y Bayesian Regression. En sus correspondientes gráficas se puede apreciar:

\paragraph{Support Vector Regression} 
El modelo Support Vector Regression ha presentado un MAE de 0.676 Gyr. Se siguen presentando dificultades para estimar correctamente todas las estrellas de los cúmulos de 0.7, y sobre todo, 4.2 Gyr.También se aprecia cierta correlación entre la edad y el error medio obtenido en las estimaciones. 
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Decision Tree Regression} 
Para el modelo Decision Tree Regression,con un MAE de 0.695 Gyr, se visualiza una nube de estimaciones muy dispersa, proporcionando pocas estrellas dentro del intervalo de confianza. Además de presentar problemas en la estimación de los cúmulos, muestra dificultades en la estimación de las edades medias, algo que no se había producido con demasiada intensidad en los modelos anteriores.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Linear Regressor} 
El modelo Linear Regressor, con un MAE de 0.951 Gyr, sigue mostrando problemas de estimación para las estrellas pertenecientes a los cúmulos. Además, la figura relativa al error muestra un error constante para todo el espectro de edad, saliéndose continuamente del margen de error asociado a las estrellas. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Bayesian Regression} 
Por último, el modelo Bayesian Regression. Este muestra los peores resultados junto con el modelo Linear Regressor, ambos con un MAE de 0.951 Gyr. Tal y como se ha visto en el modelo anterior, las figuras muestran un error constante para todas las edades del conjunto de prueba. No se encuentran picos de error excesivamente elevados, pero la constante presencia de errores de estimación lo convierten en el peor modelo de este \emph{benchmark}. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_svm_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_svm_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_svm_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_svm_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_svm_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_svm_3.pdf}}
\end{minipage}
\caption{Modelo Support Vector Regression}
\label{fig:benchA_details_2_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_dtr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_dtr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_dtr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_dtr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_dtr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_dtr_3.pdf}}
\end{minipage}
\caption{Modelo Decision Tree Regressor}
\label{fig:benchA_details_2_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_lr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_lr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_lr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_lr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_lr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_lr_3.pdf}}
\end{minipage}
\caption{Modelo Linear Regressor}
\label{fig:benchA_details_2_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_bayes_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_bayes_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_bayes_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_bayes_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchA_details_bayes_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_A_bayes_3.pdf}}
\end{minipage}
\caption{Modelo Bayesian Regression}
\label{fig:benchA_details_2_4}
\end{figure*}


\subsection{Benchmark B: Escenario de generalización}

Aquí se analiza la capacidad de generalización de todos los modelos para el problema de datación estelar. Las Figuras \ref{fig:benchB1} y \ref{fig:benchB2} muestran el rendimiento en los escenarios de evaluación B1 y B2, respectivamente.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_models.pdf}
\end{center}
\caption{Benchmark B1: Rendimiento de los modelos en función del MAE.}
 \label{fig:benchB1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_models.pdf}
\end{center}
\caption{Benchmark B2: Rendimiento de los modelos en función del MAE.}
 \label{fig:benchB2}
\end{figure}

\subsubsection{Benchmark B1} 

El Benchmark B1 se centra en analizar la precisión de los modelos estimando edades de estrellas más antiguas a las que han visto durante el entrenamiento. Obviamente, el error promedio de lo modelos ha aumentado. El mejor rendimiento se observa en la Red Neuronal, con un MAE de 1,47 Gyr. Las estimaciones detalladas se pueden ver en la Figura \ref{fig:benchB1_best_1} y Figura \ref{fig:benchB1_best_2}, donde se puede observar cómo la Red Neuronal es capaz de generalizar hasta 6 Gyr, asignando estimaciones de edad que en su mayoría se encuentran dentro del margen de confianza. La Tabla \ref{table:precisions} confirma este hecho, donde la Red Neuronal también exhibe la precisión más alta para el Benchmark B1.

\paragraph{Neural Network} 
A continuación, se muestran las 3 gráficas que detallan el rendimiento del modelo Neural Network, el cual presenta el menor MAE de este \emph{benchmark}, 1.475 Gyr. En la Figura \ref{fig:benchB1_best_1} se ve claramente que el modelo tiende a subestimar las edades estelares, consiguiendo únicamente incluir dentro del margen de error las edades más bajar. Esto es lógico ya que a partir de 4.2 Gyr son todo edades desconocidas para el modelo. En la Figura \ref{fig:benchB1_best_3} se aprecia el aumento del error medio con el aumento de la edad a estimar. En la Figura \ref{fig:benchB1_best_2} se aprecia como la predicción sigue la tendencia de una línea recta que oscila sobre el mayor valor que formaba parte del conjunto de entrenamiento. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_nnet_1.pdf}
\end{center}
\caption{Benchmark B1: Rendimiento para el modelo Neural Network.}
 \label{fig:benchB1_best_1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_nnet_2.pdf}
\end{center}
\caption{Benchmark B1: Predicción detallada para el modelo de Neural Network. Se observa la edad real (en azul), la predicción de los modelos (en naranja), y el error correspondiente (en rojo).}
 \label{fig:benchB1_best_2}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B1_nnet_3.pdf}
\end{center}
\caption{Benchmark B1: MAE en función del rango de edad del conjunto de prueba.}
 \label{fig:benchB1_best_3}
\end{figure}

\subsubsection{Benchmark B2} 

La historia es completamente diferente en el Benchmark B2. La Red Neuronal no es capaz de ser la mejor generalizando. Su error asciende hasta 1,85 Gyr, siendo superada por Linear Regressor, Random Forest, Support Vector Regression, k-Nearest Neighbors, Gaussian Process y Bayesian Regression. %TODO_DONE: mejor poner los nombres.
Este último resulta ser el mejor modelo en este escenario, con un MAE de 1.48 Gyr. De la Figura \ref{fig:benchB2_best_1} y la Figura \ref{fig:benchB2_best_2} se llega a la conclusión de que un regresor bayesiano es capaz de proporcionar edades precisas en el rango de 1 Gyr a 5 Gyr, es decir, el rango cubierto por la muestra de entrenamiento en este caso. En términos de precisión, la Tabla \ref{table:precisions} revela que el modelo SVR es el modelo ganador, seguido de cerca por el Proceso Gaussiano y el regresor linear. El modelo bayesiano, aunque tiene el MAE más bajo, presenta una precisión del 29.71 \%.

\paragraph{Bayesian Regression} 
A continuación, se muestran las 3 gráficas que detallan el rendimiento del modelo Bayesian Regression, el cual presenta el menor MAE de este \emph{benchmark}, 1.484 Gyr. Las figuras vuelven a mostrar que el modelo tiende a subestimar, algo normal si se tiene en cuenta que la edad más alta conocida en el entrenamiento es 4.2 Gyr. De la Figura \ref{fig:benchB2_best_1} se observa que la mayoría de las estimaciones caen fuera del margen de error asociado a las estrellas. En la Figura \ref{fig:benchB2_best_2} se observa que el estimador tiene con facilidad a edades cercanas a 4.2 y no alcanza valores superiores a 6 Gyr. En la línea de todo lo comentado, la Figura \ref{fig:benchB2_best_3} muestra que el error medio aumenta según aumentan las edades estelares a estimar. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_bayes_1.pdf}
\end{center}
\caption{Benchmark B2: Rendimiento para el modelo Bayessian Regression.}
 \label{fig:benchB2_best_1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_bayes_2.pdf}
\end{center}
\caption{Benchmark B2: Predicción detallada para el modelo de Bayessian Regression. Se observa la edad real (en azul), la predicción de los modelos (en naranja), y el error correspondiente (en rojo).}
 \label{fig:benchB2_best_2}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_B2_bayes_3.pdf}
\end{center}
\caption{Benchmark B2: MAE en función del rango de edad del conjunto de prueba.}
 \label{fig:benchB2_best_3}
\end{figure}

%Benchmark B1
A continuación, se detalla el resto de modelos del Benchmark B1, en las Figuras \ref{fig:benchB1_details_1_1}, \ref{fig:benchB1_details_1_2}, \ref{fig:benchB1_details_1_3} y \ref{fig:benchB1_details_1_4} se adjuntan las gráficas correspondientes al rendimiento de los modelos kNN, Random Forest, Support Vector Regression y Decision Tree Regression. En sus correspondientes gráficas se puede apreciar:

\paragraph{kNN} 
El modelo kNN presenta un MAE de 1.605 Gyr. En las figuras se observa que solo se realizan estimaciones dentro del margen de error para edades inferiores a 5 Gyr. Además, la segunda figura muestra que el modelo es incapaz de generar estimaciones por encima de 4.2 Gyr, la edad máxima que conoce del conjunto de entrenamiento.  %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Random Forest} 
En el modelo Random Forest, con un MAE de 1.709 Gyr, se observa un rendimiento similar al visto en el modelo anterior. No consigue generar edades superiores a 4.2 Gyr y se observa un aumento del error medio en estimación según aumenta la edad a estimar. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Support Vector Regression} 
El modelo Support Vector Regression, con un MAE de 1.724 Gyr, presenta diferencias respecto a los dos modelos anteriores. Este modelo sí es capaz de generar edades superiores a los 4.2 Gyr. Aún así, se mantiene el problema de subestimación y solo se consiguen estimaciones dentro del margen de error para edades inferiores a 7 Gyr. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Decision Tree Regression} 
El modelo Decision Tree Regression ha presentado un MAE de 1.621 Gyr. La primera figura ilustra los problemas que tiene el modelo para generar edades superiores a 4.2 Gyr. De hecho, parece que el modelo solo conoce estrellas de 4.2 y 3.2 Gyr, pues, tiende a esos valores durante todo el espectro de edades. Tal y como se ha visto hasta el momento, el error medio de estimación aumenta con la edad real a estimar. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_knn_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_knn_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_knn_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_knn_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_knn_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_knn_3.pdf}}
\end{minipage}
\caption{Modelo k-Nearest Neighbor}
\label{fig:benchB1_details_1_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_rf_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_rf_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_rf_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_rf_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_rf_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_rf_3.pdf}}
\end{minipage}
\caption{Modelo Random Forest}
\label{fig:benchB1_details_1_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_svm_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_svm_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_svm_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_svm_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_svm_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_svm_3.pdf}}
\end{minipage}
\caption{Modelo Support Vector Regression}
\label{fig:benchB1_details_1_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_dtr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_dtr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_dtr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_dtr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_dtr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_dtr_3.pdf}}
\end{minipage}
\caption{Modelo Decision Tree Regressor}
\label{fig:benchB1_details_1_4}
\end{figure*}


En las Figuras \ref{fig:benchB1_details_2_1}, \ref{fig:benchB1_details_2_2} y \ref{fig:benchB1_details_2_3} se adjuntan las gráficas que detallan el rendimiento de los modelos Linear Regressor, Bayesian Regression y Gaussian Process para el Benchmark B1. En sus correspondientes gráficas se puede apreciar:

\paragraph{Linear Regressor} 
El modelo Linear Regressor muestra el segundo peor rendimiento de este \emph{benchmark} con un MAE de 1.923 Gyr. La primera figura muestra los problemas que tiene el modelo para estimar todo el espectro de edades, incluidas las estrellas de 4.2 Gyr que ya conoce y para las que estima edades entre 1 y 5 Gyr. El modelo consigue generar edades de hasta 6 Gyr, pero no consigue introducir demasiadas estimaciones dentro de los márgenes de error. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Bayesian Regression} 
El modelo Bayesian Regression ha presentado los peores resultados del \emph{benchmark} con un MAE de 1.943 Gyr. En la primera figura se observa algo similar al modelos Linear Regressor, pues, presenta problemas para estimar las estrellas de 4.2 Gyr, edad que conoce del conjunto de entrenamiento. Además, se sigue observando la subestimación para el resto de edades. La segunda figura muestra en detalle el error constante que mantiene el modelo para todo el espectro de edades, consiguiendo pocas estimaciones dentro del margen de error. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Gaussian Process} 
Por último, el modelo Gaussian Process, con un MAE de 1.670 Gyr. Aquí se siguen observando para estimar la edad de 4.2 Gyr, pero no se llega al nivel de los dos modelos anteriores. Este modelo sigue la tendencia de todos los que hemos visto hasta el momento, no es capaz de estimar edades superiores a 4.2 Gyr aunque consigue introducir alguna estimación dentro del margen de error. Evidentemente, el error medio aumenta con las edades reales a estimar. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_lr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_lr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_lr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_lr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_lr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_lr_3.pdf}}
\end{minipage}
\caption{Modelo Linear Regressor}
\label{fig:benchB1_details_2_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_bayes_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_bayes_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_bayes_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_bayes_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_bayes_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_bayes_3.pdf}}
\end{minipage}
\caption{Modelo Bayesian Regression}
\label{fig:benchB1_details_2_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_gp_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_gp_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_gp_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_gp_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB1_details_gp_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B1_gp_3.pdf}}
\end{minipage}
\caption{Modelo Gaussian Process}
\label{fig:benchB1_details_2_3}
\end{figure*}


%Benchmark B2
A continuación, se detalla el resto de modelos del Benchmark B2, en las Figuras \ref{fig:benchB2_details_1_1}, \ref{fig:benchB2_details_1_2}, \ref{fig:benchB2_details_1_3} y \ref{fig:benchB2_details_1_4} se adjuntan las gráficas correspondientes al rendimiento de los modelos kNN, Random Forest, Support Vector Regression y Decision Tree Regression. En sus correspondientes gráficas se puede apreciar:

\paragraph{kNN} 
El modelo kNN ha presentado un MAE de 1.841 Gyr. En la primera imagen se observan con mucha claridad los problemas que muestra el regresor lineal para estimar edades que no sean las de los cúmulos. La segunda figura confirma que solo se estiman valores de 0.79, 1, 2.5 y 4.2 Gyr. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Random Forest} 
El modelo Random Forest, con un MAE de 1.852 Gyr, muestra un rendimiento similar al kNN. En este caso la nube de puntos de la primera figura representa una serie de estimaciones menos ajustadas a las edades de los cúmulos, aunque se sigue apreciando gran población de estimaciones en esas edades. Como parece lógico, al aumentar la edad real a estimar, aumenta el error medio de la estimación. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Support Vector Regression} 
El modelo Support Vector Regression, con un MAE de 1.507 Gyr, muestra una nube de estimaciones que tiende a buscar la edad de las estrellas que no conoce, mostrando un rendimiento más natural que los dos anteriores. Aunque se consiguen estimaciones cercanas a los 6 Gyr, el modelo muestra dificultad para meter en el margen de error las estimaciones de estrellas de más de 4 Gyr. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.


\paragraph{Decision Tree Regression} 
El modelo Decision Tree Regression, con un MAE de 1.901 Gyr, muestra un comportamiento similar al kNN, en que se ve con claridad si tendencia a estimar la edad de los cúmulos para todas las estrellas del conjunto de test. %TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_knn_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_knn_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_knn_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_knn_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_knn_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_knn_3.pdf}}
\end{minipage}
\caption{Modelo k-Nearest Neighbor}
\label{fig:benchB2_details_1_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_rf_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_rf_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_rf_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_rf_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_rf_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_rf_3.pdf}}
\end{minipage}
\caption{Modelo Random Forest}
\label{fig:benchB2_details_1_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_svm_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_svm_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_svm_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_svm_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_svm_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_svm_3.pdf}}
\end{minipage}
\caption{Modelo Support Vector Regression}
\label{fig:benchB2_details_1_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat[dtr]{\label{fig:benchB2_details_dtr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_dtr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_dtr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_dtr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_dtr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_dtr_3.pdf}}
\end{minipage}
\caption{Modelo Decision Tree Regression}
\label{fig:benchB2_details_1_4}
\end{figure*}


En las Figuras \ref{fig:benchB2_details_2_1}, \ref{fig:benchB2_details_2_2} y \ref{fig:benchB2_details_2_3} se adjuntan las gráficas que detallan el rendimiento de los modelos Linear Regressor, Neural Network y Gaussian Process para el Benchmark B2. En sus correspondientes gráficas se puede apreciar:

\paragraph{Linear Regressor} 
El modelo Linear Regressor, con un MAE de 1.561 Gyr, muestra un rendimiento similar a la máquina de vectores soporte. Te tiene una gran nube de estimaciones que caen dentro del margen de error para estrellas de hasta 4 Gyr, pero, para edades mayores presenta problemas en la estimación. La segunda figura muestra que se produce un error contante en la estimación de todo el espectro de edades.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Neural Network} 
La red neuronal, a diferencia del resto de escenarios, es uno de los modelos que peor rendimiento presenta junto con Decision Tree Regression, mostrando un MAE de 1.853 Gyr. En la primera figura se observa que las estimaciones de todas las edades van de 0.7 a 4.2 Gyr, siendo estas las edades inferior y superior de los cúmulos.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\paragraph{Gaussian Process} 
El último modelo de este \emph{benchmark} es Gaussian Process, el cual ha presentado un MAE de 1.624 Gyr. En la primera figura se puede observar un comportamiento ya conocido, pues, hasta las estrellas de 4 Gyr, consigue estimaciones aproximadas. Pero, cuando la edad a estimar pasa de 4 Gyr, se vuelve a demostrar la incapacidad para extrapolar y la tendencia a subestimar edades.
%TODO_DONE: Si se ponen gráficas es para comentar algo sobre ellas, así que adelante.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_lr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_lr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_lr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_lr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_lr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_lr_3.pdf}}
\end{minipage}
\caption{Modelo Linear Regressor}
\label{fig:benchB2_details_2_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_nnet_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_nnet_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_nnet_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_nnet_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_nnet_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_nnet_3.pdf}}
\end{minipage}
\caption{Modelo Neural Network}
\label{fig:benchB2_details_2_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_gp_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_gp_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_gp_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_gp_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchB2_details_gp_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_B2_gp_3.pdf}}
\end{minipage}
\caption{Modelo Gaussian Process}
\label{fig:benchB2_details_2_3}
\end{figure*}


\subsection{Benchmark C: Rendimiento sobre la muestra de control}

Se muestra el MAE y la precisión de cada método para el \emph{benchmark} de control en la Figura \ref{fig:benchC} y en la Tabla \ref{table:precisions}, respectivamente. En esta ocasión, los tres mejores métodos son el Proceso Gaussiano, la Red Neuronal y su Stacking. Entre estos tres, destaca el Proceso Gaussiano. En la Figura \ref{fig:benchC_best_1} y Figura \ref{fig:benchC_best_2} se pueden inspeccionar las predicciones de las edades estelares usando este método frente a las edades de referencia para las estrellas de ese set. Proceso Gaussiano es el modelo con mayor precisión: $40.62\%$ de las predicciones caen dentro del margen de confianza del conjunto de datos. Para el Sol, Proceso Gaussiano predice una edad de 3,88 Gys frente a una edad aceptada de 4,6 Gyr, subestimándola. De hecho, el modelo tiende a subestimar ligeramente la mayoría de las edades. Se observa este comportamiento en todos lo modelos salvo en kNN y dtr. 

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_models.pdf}
\end{center}
\caption{Benchmark C: Rendimiento de los modelos en función del MAE.}
 \label{fig:benchC}
\end{figure}

%Precision for the SUN
Respecto a la precisión en las estimaciones para la edad del Sol, 4,6 Gyr, se proporciona en la Tabla \ref{table:sun_results} la edad específica obtenida en cada uno de los modelos. Todos los modelos subestiman, y rf obtiene la predicción más cercana, seguido de dtr y kNN.


\begin{table}[H]
\centering
\scalebox{0.6}{
\begin{tabular}{l|ccccccccc}  
\toprule
\textbf{Modelos}  & nnet & lr & dtr & rf & svm & bayes & knn & gp & stacking \\
\midrule
Sol (4.6 Gyr)  & 4.02 & 3.92 & 4.49 & 4.76 & 3.81 & 3.91 & 4.49 & 3.88 & 4.02\\
\bottomrule
\end{tabular}
}%end of scalebox
\caption{Edad estimada para el Sol en Gyr. El método más preciso es rf. }\label{table:sun_results}
\end{table}
%TODO_DONE: Jarmi, yo creo que es mejor que esta y las otras gráficas las metas todas juntas en una gráfica grande o en un par de ellos, en filas de 3, una fila por modelo, y luego comentas. Haz lo mismo para los anteriores benchmarks, que así quedará más bonito el PDF.
\paragraph{Gaussian Process} 
A continuación, se muestran las 3 gráficas que detallan el rendimiento del modelo Gaussian Process. El mejor modelo en este \emph{benchmark}, con un MAE de 0.837 Gyr. En las dos primeras figuras se puede observar la precisión de las estimaciones, ya que, se podría decir que oscilan en torno a las edades reales. El modelo encuentra dificultad en estimar edades cercanas a los 7 Gyr, así como la edad del Sol que no se encuentra en el margen de error permitido.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_gp_1.pdf}
\end{center}
\caption{Benchmark C: Rendimiento para el modelo Gaussian Process. El punto amarillo se corresponde con la representación de la estimación de la edad del Sol.}
 \label{fig:benchC_best_1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_gp_2.pdf}
\end{center}
\caption{Benchmark C: Predicción detallada para el modelo de Gaussian Process. Se observa la edad real (en azul), la predicción de los modelos (en naranja), y el error correspondiente (en rojo).El punto amarillo se corresponde con la representación de la estimación de la edad del Sol.}
 \label{fig:benchC_best_2}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/Experimentos/B_C_gp_3.pdf}
\end{center}
\caption{Benchmark C: MAE en función del rango de edad del conjunto de prueba.}
 \label{fig:benchC_best_3}
\end{figure}

A continuación, se detalla el resto de modelos del Benchmark C, en las Figuras \ref{fig:benchC_details_1_1}, \ref{fig:benchC_details_1_2}, \ref{fig:benchC_details_1_3} y \ref{fig:benchC_details_1_4} se adjuntan las gráficas correspondientes al rendimiento de los modelos Stacking, Neural Network, kNN y Random Forest. En sus correspondientes gráficas se puede apreciar:

\paragraph{Stacking} 
El modelo Stacking ha presentado un MAE de 0.991 Gyr. En la primera gráfica se vuelve a observa cierta dificultad para estimar estrellas cercanas a los 7 Gyr, y además, se aprecia mayor problema en la estimación de las estrellas más jóvenes. Este modelo sigue sin estimar el Sol dentro del margen de error. En este caso, se obtiene mayor error medio en la estimación de las estrellas más viejas.

\paragraph{Neural Network} 
La red neuronal, con un MAE de 1.098 Gyr, muestra un rendimiento similar al de los modelos anteriores. Presenta problemas en la estimación de las estrellas mayores de 7 Gyr y no consigue estimar la edad del Sol dentro del margen de error. Las dos primeras gráficas ilustran cierta subestimación en las estimaciones de todo el espectro de edades.

\paragraph{kNN} 
El modelo kNN, con un MAE de 1.734 Gyr, presenta, a simple vista, mayor dispersión en la nube de edades estimadas. En las dos primeras figuras se observan edades superiores a 10 y 12 Gyr para estrellas de 7 Gyr. Por otro lado, se tiene una mejor estimación de la edad del Sol que con los modelos anteriores.

\paragraph{Random Forest} 
El modelo Random Forest, con un MAE de 1.006 Gyr, también presenta una buena estimación de la edad del Sol. Además, las dos primeras figuras muestran la oscilación de las estimaciones en torno a las edades reales, aunque la mayoría no lo suficientemente buenas como para entrar en el margen de error.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_stacking_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_stacking_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_stacking_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_stacking_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_stacking_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_stacking_3.pdf}}
\end{minipage}
\caption{Modelo Stacking}
\label{fig:benchC_details_1_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_nnet_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_nnet_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_nnet_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_nnet_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_nnet_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_nnet_3.pdf}}
\end{minipage}
\caption{Modelo Neural Network}
\label{fig:benchC_details_1_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_knn_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_knn_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_knn_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_knn_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_knn_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_knn_3.pdf}}
\end{minipage}
\caption{Modelo k-Nearest Neighbor}
\label{fig:benchC_details_1_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_rf_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_rf_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_rf_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_rf_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_rf_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_rf_3.pdf}}
\end{minipage}
\caption{Modelo Random Forest}
\label{fig:benchC_details_1_4}
\end{figure*}

En la Figura \ref{fig:benchC_details_2} se adjuntan las gráficas que detallan el rendimiento de los modelos Support Vector Regression, Decision Tree Regression, Linear Regressor y Bayesian Regression para el Benchmark C. En sus correspondientes gráficas se puede apreciar:

\paragraph{Support Vector Regression} 
El modelo de máquina de vectores soporte ha presentado un MAE de 1.278 Gyr. Las dos primeras figuras ilustran la tendencia del modelo para subestimar las edades de las estrellas a partir de los 3 Gyr. Además, en la tercera gráfica, se observa mayor error medio para la estimación de las estrellas más viejas.

\paragraph{Decision Tree Regression} 
El modelo Decision Tree Regression, con un MAE de 2.113 Gyr, muestra el peor rendimiento del \emph{benchmark}. Las dos primeras figuras muestran que la mayoría de las estimaciones están muy lejos de entrar dentro del margen de error asociado a las edades. Por contra, la estimación de la edad del Sol es una de las pocas edades que sí se encuentra dentro del margen de error.

\paragraph{Linear Regressor} 
El modelo Linear Regressor ha presentado un MAE de 1.297 Gyr. Sus dos primeras gráficas muestran subestimación en las estimaciones a partir de los 3 Gyr. Además, la mayor parte de estimaciones se encuentran fuera del margen de error, incluida la edad del Sol. La figura tres muestra un aumento del error medio con el aumento de edad a estimar.


\paragraph{Bayesian Regression} 
Por último, se tiene el modelo Bayesian Regression, el cual ha presentado un MAE de 1.297 Gyr. Su comportamiento es similar al del modelo de regresión lineal, tomando un valor similar y una estimación de edades muy parecida.

\begin{figure*}[h]
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_svm_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_svm_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_svm_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_svm_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_svm_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_svm_3.pdf}}
\end{minipage}
\caption{Modelo Support Vector Regression}
\label{fig:benchC_details_2_1}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_dtr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_dtr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_dtr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_dtr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_dtr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_dtr_3.pdf}}
\end{minipage}
\caption{Modelo Decision Tree Regression}
\label{fig:benchC_details_2_2}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_lr_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_lr_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_lr_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_lr_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_lr_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_lr_3.pdf}}
\end{minipage}
\caption{Modelo Linear Regressor}
\label{fig:benchC_details_2_3}
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_bayes_1}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_bayes_1.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_bayes_2}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_bayes_2.pdf}}
\end{minipage}%
\begin{minipage}{.35\linewidth}
\centering
\subfloat{\label{fig:benchC_details_bayes_3}\includegraphics[width=\linewidth]{Figuras/Experimentos/B_C_bayes_3.pdf}}
\end{minipage}
\caption{Modelo Bayesian Regression}
\label{fig:benchC_details_2_4}
\end{figure*}


\subsection{Conclusiones de la comparativa}

Comparando los resultados de los Benchmark A (Figura \ref{fig:benchA_models}) y C (Figura \ref{fig:benchC}), se puede concluir que: %TODO_DONE: pon todo esto en items dentro de un entorno enumerate
\begin{enumerate}
\item Los modelos ganadores son comunes Neural Network, Gaussian Process y su Stacking.
\item k-Nearest Neighbors y Decision Tree Regression sufren una degradación considerable de su rendimiento, ya que dependen en gran medida de la distribución de datos utilizada durante su entrenamiento.
\item Bayesian Regression y Linear Regressor son similares, mostrando un incremento similar en sus correspondientes MAEs, pero al mismo tiempo ofreciendo cierta estabilidad entre escenarios.
\end{enumerate}


Al observar la Tabla \ref{table:precisions} después de conocer el rendimiento de todos los modelos, además de lo comentado en cada uno de los benchmarks, se llega a la conclusión de que: a) salvo para el Benchmark B2, nnet presenta una precisión alta en comparación con el resto de modelos, y b), salvo para el Benchmark B2, lr y bayes presentan una precisión muy inferior a la conseguida por el modelo de mejor rendimiento.

\begin{table}[H]
\centering
\scalebox{0.6}{
\begin{tabular}{l|ccccccccc}  
\toprule
Benchmark & nnet & lr & dtr & rf & svm & bayes & knn & gp & stacking \\
\midrule
\textbf{A}  & 73.23 & 35.43 & 63.78 & 60.63 & 46.46 & 32.28 & \textbf{77.95} & 62.20 & 62.99\\
\textbf{B1}  & \textbf{59.84} & 29.92 & 51.18 & 48.03 & 37.79 & 28.35 & 55.91 & 51.97 & n/a \\
\textbf{B2}  & 28.45 & 30.96 & 21.34 & 25.94 & \textbf{33.05} & 29.71 & 25.52 & 30.96 & n/a\\
\textbf{C}  & 34.37 & 21.87 & 9.37 & 21.87 & 12.50 & 21.87 & 15.62 & \textbf{40.62} & 34.37\\
\bottomrule
\end{tabular}
}%end of scalebox
\caption{Precisión de todos los métodos en los diferentes benchmarks. La precisión se mide como el porcentaje de estimaciones de edad que caen dentro del margen de confianza asociado a cada estrella.}\label{table:precisions}
\end{table}


\chapter{Meta-learning para estimación de edades estelares}

\section{Introducción}

En este trabajo, además de realizar un estudio comparativo sobre los modelos tradicionales de Inteligencia Artificial para regresión de edades estelares, se propone abordar por primera vez, el aplicar técnicas de meta-learning a este problema. El meta-learning se define como el proceso de aprender a aprender con pocas muestras, o explicado de un modo mas técnico, sería el modo de entrenamiento de un modelo en varias tareas de aprendizaje, de modo que el modelo sea capaz de resolver nuevas tareas utilizando una pequeña cantidad de muestras. 

En particular, en este proyecto se estudia la aplicación del algoritmo MAML (model-agnostic meta-learning) \cite{finn2017modelagnostic}, para el problema de la estimación de edades estelares. Este algoritmo se denomina agnóstico del modelo porque es compatible con cualquier modelo entrenado con descenso de gradiente y aplicable a una variedad de diferentes problemas de aprendizaje, incluyendo clasificación, regresión y aprendizaje por refuerzo. 

Para llevar a cabo este estudio, se parte de \cite{finn2017modelagnostic}, donde se propone un algoritmo de meta-learning y agnóstico del modelo con enfoque en redes neuronales profundas. La idea clave de este método es entrenar los parámetros iniciales del modelo de forma que tenga un rendimiento máximo en una nueva tarea después de que los parámetros se hayan actualizado a través de uno o más pasos de gradiente calculados con una pequeña cantidad de datos de esa nueva tarea.

La contribución principal de este trabajo fin de máster reside en un algoritmo de modelado simple e independiente de las tareas para el meta-learning sobre datación estelar, capaz de conseguir un aprendizaje rápido en una nueva tarea a través de una pequeña cantidad de actualizaciones de gradiente. Es decir, vamos a emplear y evaluar el rendimiento de MAML en un escenario de meta-learning para la regresión de la edad de las estrellas. 

\section{Model-Agnostic Meta-Learning Algorithm}
\label{sec:metalearning}
En esta sección se comienza describiendo los detalles de MAML \cite{finn2017modelagnostic}. Durante el meta-learning, el modelo se entrena para poder adaptarse a un número grande o infinito de tareas. A continuación, se presenta una aproximación genérica de una tarea, permitiendo abordar una variedad de problemas de aprendizaje, desde la clasificación hasta el aprendizaje por refuerzo.

Cada tarea consiste en una función de pérdidas, una distribución de las observaciones iniciales, una distribución de transición y una longitud de episodio. El modelo genera muestras con la longitud del episodio y la función de pérdidas proporciona retroalimentación específica para cada tarea.
En el escenario de meta-learning, se tiene en cuenta una distribución de todas las tareas a las que se quiere adaptar el modelo. En la configuración del aprendizaje \emph{K-shot}, el modelo se entrena para que aprenda nuevas tareas de la distribución total, usando únicamente K muestras de la observación inicial y la retroalimentación proporcionada por la función de pérdidas para cada tarea. 

Durante el metaentrenamiento, se muestrea una tarea proveniente de la distribución total, el modelo se entrena con K muestras y se retroalimenta con la correspondiente función de pérdidas de cada tarea, y después se prueba sobre nuevas muestras de la misma tarea. Entonces, el modelo mejora considerando cómo varía el error de prueba sobre nuevos datos, provenientes de las observaciones iniciales, respecto a los parámetros.

Para el desarrollo del algoritmo se presenta un enfoque explícito para el problema. Ya que el modelo se ajustará utilizando una regla de aprendizaje basada en gradientes, el objetivo es hacer aprender a un modelo de tal manera que esta regla de aprendizaje basada en gradientes pueda hacer un avance rápido en nuevas tareas extraídas de la distribución total sin sobreajuste. Por tanto, el objetivo es encontrar los parámetros del modelo que sean sensibles a los cambios de las tareas, de modo que pequeños cambios en los parámetros producirán grandes mejoras en la función de pérdidas de cualquiera tarea. 

A continuación, se detalla paso a paso del algoritmo MAML. Inicialmente se requiere la distribución de tareas a la que se quiere adaptar el modelo, además del tamaños de los pasos de actualización de hiperparámetros.
Entrando en detalle en cada paso del algoritmo, en primer lugar, se inicializa de forma aleatoria el vector de parámetros con el que se parametriza el modelo. El bucle principal del algoritmo comienza con un muestreo de tareas sobre la distribución inicial. Para cada una de estas tareas se evalúa la función de pérdidas respecto a las K muestras seleccionadas. A continuación, se realiza la adaptación de parámetros mediante el descenso de gradiente. Una vez se ha finalizado con el conjunto de tareas, se actualiza el vector de parámetros que parametriza el modelo.

\vspace{1cm}

\begin{algorithm}[H]
 \KwData{p(T): distribution over tasks}
 \KwData{$\alpha$, $\beta$ : step size hyperparameters}
 randomly initialize $\theta$ \;
 \While{not done}{
 Sample batch of tasks $T_{i}$ $\~$ $p(T)$\;
  \For{all $Ti$}{
  Evaluate $\nabla_{\theta}$ $L_{T_{i}}(f_{\theta})$ with respect to K examples\;
   Compute adapted parameters with gradient descent: $\theta_{i}$ = $\theta$ − $\alpha$ $\nabla_{\theta}$ $L_{Ti}(f_{\theta})$\;
  }
  Update $\theta$ ← $\theta$ − $\beta$ $\nabla_{\theta}$ $\sum_{Ti \~ p(T)}$ $L_{Ti}(f_{\theta´_{i}})$
 }
 \caption{Model-Agnostic Meta-Learning}
\end{algorithm}

%TODO: creo que sería buena idea meter el algoritmo que aparece en el paper de MAMl. Sería copiar el algoritmo 1 que aparece en el artículo y ahbalr un poco de él.

\section{MAML en regresión}

Para estudiar el rendimiento de un algoritmo MAML sobre el problema de regresión de estimación de edades estelares, se parte del desarrollo realizado por Chelsea Finn, entre otros \cite{finn2017modelagnostic}. 

En su trabajo se presenta una evaluación experimental con el objetivo de responder a tres cuestiones: 1) ¿Será capaz el algoritmo MAML de reproducir un aprendizaje rápido sobre las nuevas tareas?, 2) ¿Podrá ser usado este algoritmo para implementar metaentrenamiento en diferentes dominios, incluyendo regresión, clasificación y aprendizaje por refuerzo? y 3) ¿Puede el modelo aprendido continuar mejorando su rendimiento con actualizaciones de gradiente adicionales?

Los investigadores proponen tres escenarios de aplicación para tratar de responder a estas preguntas: 1) un problema simple de regresión donde se ilustran los principios básicos del algoritmo MAML, 2) un problema de reconocimiento de imágenes sobre los datasets Omniglot y MiniImagenet y 3) un problema de aprendizaje por refuerzo en el que se construyen varios conjuntos de tareas basadas en entornos de control continuo.

Conociendo los 3 escenarios expuestos en esta investigación y con el fin de abordar el problema de regresión de datación de estrellas, se toma como referencia el escenario de regresión simple. En este escenario, cada tarea implica una regresión de la entrada a la salida de una onda sinusoidal, donde la amplitud y la fase de la sinusoide varían en cada tareas.

Para la generación de los senos se necesitan conocer los valores que pueden tomar la amplitud y la fase de los senos. Una vez definido esto, se parte de un vector equiespaciado con tantas muestras como puntos se quiere que tenga el seno. Sobre este vector se aplica la función seno con su correspondiente valor de fase y se multiplica por un valor amplitud. Así se obtienen tantos vectores senos como vectores se han definido para el tamaño de \emph{batch}.

En la fase de entrenamiento, se generan 25 vectores, con los 20 puntos correspondientes al seno, por cada una de las 70000 iteraciones de metaentrenamiento. Son 25 vectores porque el tamaño de \emph{batch} es igual a 25. Después, en la etapa de prueba, se producen 600 iteraciones en las que se genera 1 vector de 20 puntos para cada iteración. En esta ocasión, el tamaño de \emph{batch} es igual a 1. Por lo tanto, el algoritmo tiene como entrada 25 vectores de 20 elementos por cada una de las 70000 iteraciones del metaentrenamiento y 1 vector de 20 elementos por cada una de las 600 iteraciones de prueba. De los 20 puntos que componen el seno, 10 se emplean íntegramente en el proceso de descenso de gradiente, por eso se denomina \emph{10-shot}. %TODO_DONE: al final cuantos vectores, de qué dimensiones, que se entienda lo que ve el algoritmo por dentro


La función de pérdidas se corresponde con el error cuadrático medio entre la predicción y el valor real. El modelo regresor se basa en una red neuronal con 2 capas ocultas de tamaño 40 cada una, con función de activación ReLU. Para el entrenamiento del MAML, se utiliza un valor de actualización de gradiente igual a 10 con un tamaño fijo de \emph{step} de 0.01 y se emplea Adam como metaoptimizador.


Para evaluar su rendimiento, se ajusta un solo modelo con un número variable las muestras empleadas para el correspondiente \emph{K-shot} y se compara con dos \emph{baselines}: 1) preentrenando sobre todas las tareas, y 2), usando un oráculo que reciba la amplitud y fase real de cada sinusoide.

Las Figuras \ref{fig:sinusoid_results_1}, \ref{fig:sinusoid_results_2} y \ref{fig:sinusoid_results_3} ilustran los resultados de esta comparativa para diferentes valores de K. Aquí se representa el MSE en función del valor de la iteración de actualización del gradiente, mostrando mejor resultado en las últimas actualizaciones de gradiente. Salvo para el oráculo, que ya conoce los valores de amplitud y fase, por lo que su valor de MSE es igual a 0 todo el tiempo.

En estas gráficas se puede observar la diferencia de rendimiento que se obtiene al comparar el algoritmo MAML frente al modelo preentrenado. En el mejor de los rendimientos obtenidos, el modelo preentrenado presenta un MSE de 1.5, mientras que el MAML presenta un MSE próximo a 0. Por otro lado, el oráculo presenta mejores resultados que el MAML para las primeras iteraciones de la actualización del gradiente, ya que toma un valor perpetuo igual a 0, pero el MAML llega a tomar valores comparables con la configuración \emph{10-shot} e incluso similares con la configuración \emph{20-shot}, con valores muy próximos a 0.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/sinusoid_1.pdf}
\end{center}
\caption{Resultados del estudio de regresión sobre las ondas sinusoidales con K = 5.}
 \label{fig:sinusoid_results_1}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/sinusoid_2.pdf}
\end{center}
\caption{Resultados del estudio de regresión sobre las ondas sinusoidales con K = 10.}
 \label{fig:sinusoid_results_2}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/sinusoid_3.pdf}
\end{center}
\caption{Resultados del estudio de regresión sobre las ondas sinusoidales con K = 20.}
 \label{fig:sinusoid_results_3}
\end{figure}

\section{MAML para datación estelar}
\label{sec:maml}

En esta sección, se detalla la aplicación del algoritmo MAML sobre el problema de la estimación de edades estelares. En primer lugar, se analiza la inyección de los datos en el algoritmo, teniendo en cuenta que las características de las estrellas que se emplean para predecir la edad son las mismas que se han utilizado en el Benchmarking principal de este proyecto, las cuales se detallan en la Sección \ref{sec:data}. A continuación, se profundiza en el propio funcionamiento del algoritmo, donde se implementan los procesos comentados en el apartado anterior. Y finalmente, se analizan los resultados obtenidos por el algoritmo comparando diferentes configuraciones para la arquitectura de la red neuronal.


\subsection{Inyección de los datos} 

Como se ha comentado en la introducción de este apartado, el set de datos elegido para estimar la edad estelar es el mismo que se detalla en la Sección \ref{sec:data}. Este set se compone de de 8 características asociadas a cada una de las estrellas que forman el dataset: temperatura estelar efectiva, logaritmo de la gravedad superficial, masa estelar, radio estelar, contenido de hierro sobre hidrógeno, luminosidad, periodo de rotación y la edad de la estrella.

Este dataset es idéntico al que se ha detallado en la Sección \ref{sec:data}, ya que se parte de un conjunto de datos inicial sobre el que es necesario aplicar una serie de filtros asociados a la física detrás de la girocronolgía. Las características que se emplean para estimar la edad de las estrellas son: masa estelar, radio estelar, temperatura efectiva, luminosidad, metalicidad, logaritmo de la gravedad superficial y periodo de rotación.

Tras es filtrado, el conjunto de datos cuenta con un número relativamente reducido de muestras en comparación con los experimentos de regresión estudiados en \cite{finn2017modelagnostic}. Por tanto, ya que la el conjunto de datos completo incluye valores de error por exceso y defecto para cada una de las características, se aumenta el tamaño del dataset siguiendo una distribución normal. Esta normal tiene como rango inferior el valor de cada característica menos su error por defecto y como rango superior, el valor de la característica más el error por exceso. Además, la función de la distribución normal tiene un parámetro asociado al número de muestras que se generan a partir de las características y sus valores de error asociado, este parámetro toma un valor igual a 20. Este proceso permite pasar de un conjunto de datos de 637 estrellas a un conjunto de datos de más de 13000 estrellas.

En la práctica esto se traduce en 10600 vectores de 7 elementos, es decir, sus características, para el proceso de metaentrenamiento y 2651 vectores, con sus correspondientes 7 elementos, para el proceso de prueba. Es necesario tener en cuenta que el tamaño del \emph{batch} en el proceso de entrenamiento es igual a 20, por lo que las iteraciones totales de metaentrenamiento se obtienen de distribuir los 10600 vectores entre 20. Por otro lado, el tamaño de \emph{batch} del proceso de prueba es igual a 1, por lo que, no será necesario hacer un reparto de los vectores en cada iteración. %TODO_DONE: explica mejor cómo se genera, qué incluye el dataset, etc. Se trata de dar mas detalles. Explicando cuántos vectores, dimensiones, entre qué intervlaos se usa la función uniforme, pseudocódigo, etc. Hay que ser un pelín mas técnico.

La división del conjunto total de estrellas en entrenamiento y prueba tiene una relación 80/20 respectivamente. Además, las edades se ordenan de forma creciente, por lo que, el conjunto de entrenamiento contiene estrellas de hasta 4.2 Gyrs de edad, mientras que el conjunto de prueba comprende edades de entre 4.2 Gyrs y 18.8 Gyrs.

Durante la fase de entrenamiento del modelo, al algoritmo se le inyectan conjuntos de 20 estrellas, o lo que es lo mismo, el tamaño del \emph{batch} es igual a 20, tal y como se ilustra en la Figura \ref{fig:input_data_train}. De estas 20 muestras, 10 se emplean en el proceso de actualización de gradiente, es por esto que el experimento se cataloga como \emph{few-shot} con K = 10, es decir, \emph{10-shot}. Para la fase de prueba el tamaño del \emph{batch} es igual a 1, por lo que, en cada iteración del \emph{test} se inyecta una estrella. En la Figura \ref{fig:input_data_test} se observa este proceso de forma gráfica.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/train_data.pdf}
\end{center}
\caption{Esquema de la inyección de datos durante la fase de entrenamiento.}
 \label{fig:input_data_train}
\end{figure}

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/test_data.pdf}
\end{center}
\caption{Esquema de la inyección de datos durante la fase de prueba.}
 \label{fig:input_data_test}
\end{figure}


\subsection{Procese de aprendizaje} 

Según se ha comentado en la sección anterior, el algoritmo procesa \emph{batches} de 20 estrellas durante el proceso de entrenamiento, 10 de estas estrellas pasan a ser directamente \emph{inputs} de la red neuronal del modelo y le proporcionan información del ajuste de pesos a las otras 10 estrellas que participarán en el proceso de actualización de gradiente. Esas 10 estrellas restantes, pasan por un proceso de actualización de gradiente en el que suceden 10 pasos, es decir, se producen 10 actualizaciones del gradiente hasta llegar a la estimación óptima. En cada una de las actualizaciones se produce una corrección de los pesos del modelo y se obtiene una medida de error asociada a la estimación de la edad por parte de la red neuronal con dichos pesos. La Figura \ref{fig:core_maml_train} ilustra el funcionamiento descrito.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/maml_core_train.pdf}
\end{center}
\caption{Esquema del funcionamiento interno del modelo durante el proceso de entrenamiento.}
 \label{fig:core_maml_train}
\end{figure}

En el proceso de pruebas se sigue el mismo procedimiento, pero a diferencia de la fase de entrenamiento, el tamaño de \emph{batch} es igual a 1. Esto permite, en cada iteración del \emph{test}, obtener la edad estimada para cada estrella y las perdidas asociadas en cada uno de los 10 pasos de actualización de gradiente. Además, se obtiene la estimación y las pérdidas de la red neuronal sin la corrección de sus pesos, es decir, sin actualización del gradiente. La Figura \ref{fig:core_maml_test} ilustra el funcionamiento descrito.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/maml_core_test.pdf}
\end{center}
\caption{Esquema del funcionamiento interno del modelo durante el proceso de prueba.}
 \label{fig:core_maml_test}
\end{figure}


\subsection{Resultados obtenidos} 
\label{sub:maml_result}
Para evaluar los resultados obtenidos en este experimento, se trabaja con la misma métrica que se utiliza en el artículo original, el error cuadrático medio. Esta medida se obtiene aplicando la función de pérdidas (MSE) sobre la estimación del modelo y la edad real de la estrella. 

Al finalizar la fase de prueba, se obtiene un vector con 11 posiciones para cada estrella del conjunto de \emph{test}, la primera posición del vector se corresponde con el error obtenido sin descenso de gradiente y las 10 posiciones restantes con el error en cada una de las actualizaciones de gradiente.


Con el fin de encontrar la mejor arquitectura para la red neuronal, se realizan diferentes simulaciones variando la composición en cuanto al número de capas ocultas del modelo y el número de unidades de cada capa. La arquitectura publicada en el artículo original esta compuesta por 2 capas ocultas de 40 unidades cada una, además, se propone: 1) 2 capas ocultas de 20 unidades cada una, 2) 3 capas ocultas de 20 unidades cada una y 3) 1 capa oculta con 40 unidades.
La Figura \ref{fig:mse_nnet} ilustra los resultados obtenidos al comparar las diferentes arquitecturas.

\begin{figure}[H]
\begin{center}
 \includegraphics[width=0.8\linewidth]{Figuras/MAML/MSE.pdf}
\end{center}
\caption{Comparación del MSE para las distintas configuraciones de la red neuronal}
 \label{fig:mse_nnet}
\end{figure}

Tras analizar estos resultados, se concluye que el modelo que mejores resultados presenta es la red neuronal cuya arquitectura está formada por 3 capas ocultas y 20 unidades en cada una. Desde la primera iteración del gradiente, muestra un MSE menor al de todas las demás arquitecturas.

Por otro lado, la arquitectura que muestra los peores resultados de experimento es la red neuronal formada por una sola capa oculta de 40 unidades. Se observa un rendimiento considerablemente peor desde la primera hasta la última iteración de actualización de gradiente.

Sin tener en cuenta esta última configuración, las 3 arquitecturas restantes se aproximan, en las últimas actualizaciones de gradiente, a los resultados obtenidos por el oráculo (MSE = 0). En la Tabla \ref{table:mse_maml} se detallan los valores exactos.

\begin{table}[H]
\centering
\scalebox{0.6}{
\begin{tabular}{l|ccccccccccc}  
\toprule
Arquitectura & Act. 0 & Act. 1 & Act. 2 & Act. 3 & Act. 4 & Act. 5 & Act. 6 & Act. 7 & Act. 8 & Act. 9 & Act. 10 \\
\midrule
\textbf{[40 40]}  & 5.69 & 3.72 & 2.11 & 1.13 & 0.65 & 0.40 & 0.26 &  0.18 &  0.12 &  0.08 & 0.06\\
\textbf{[20 20]}  & 5.94 & 4.40 & 3.00 & 1.90 & 1.19 & 0.77 & 0.52 & 0.37 & 0.26 &  0.19 & 0.14\\
\textbf{[20 20 20]}  & 5.75 &  3.27 &  1.42 & 0.63 & 0.32 &  0.18 & 0.10 & 0.06 & 0.03 & 0.02 & 0.01\\
\textbf{[40]}  & 5.98 & 5.21 & 4.49 & 3.84 & 3.27 & 2.76 & 2.33 & 1.96 & 1.66 & 1.41 & 1.20\\
\bottomrule
\end{tabular}
}%end of scalebox
\caption{MSE para las diferentes arquitucturas y cada una de las actualizaciones de gradiente.}\label{table:mse_maml}
\end{table}


\chapter{Conclusiones}

\section{Modelos clásicos de IA para datación de estrellas}

En la primera parte de este trabajo se ha presentado un análisis exhaustivo comparando el estado del arte en modelos en regresión de Inteligencia Artificial entrenados y probados para solucionar el problema de datación estelar. En base a los resultados obtenidos en este estudio, se informa de los siguientes hallazgos sobre el rendimiento y la capacidad de generalización de los modelos de regresión para la estimación de edades estelares.

En primer lugar, el estudio demuestra que un modelo de datación estelar basado en una Red Neuronal como la desarrollada en este proyecto, proporciona resultados notables en términos de compensación entre generalización y precisión. Los experimentos revelan que el rendimiento del modelo nnet es bueno en los Benchmarks A y C, donde se prueba sobre un conjunto de estrellas aleatorias de la base de datos y sobre un conjunto de control, respectivamente, pero también presenta buenos resultados en el Benchmark B1, donde se pone a prueba su capacidad de generalizar sobre estrellas de edades desconocidas. Es un modelo simple, un MLP con 3 capas ocultas, que podría extenderse (usando capas 1D CNN) posiblemente ofreciendo mejores resultados. Se deja la puerta abierta para futuras investigaciones. Si los profesionales del campo pretenden buscar la solución que proporcione el menor error, el mensaje es: debe utilizarse un modelo de stacking que combine procesos gaussianos y redes neuronales, esta combinación presenta los mejores rendimientos del Benchmark A y los segundos mejores del Benchmark C, además de presentar buenas precisiones en ambos escenarios de generalización, aunque no las mejores. Finalmente, se recomienda una regresión bayesiana si los datos de entrenamiento disponibles pertenecen principalmente a cúmulos de estrellas.

En segundo lugar, es importante destacar que \emph{todos} los modelos tienden a subestimar en sus estimaciones, y no solo en el Benchmark B1, donde sería natural debido a que los modelos se entrenan con estrellas jóvenes y desconocen un amplio rango de edades. Por lo tanto, se ve una interesante línea de trabajo futura en relación a la reducción de este sesgo.

En tercer lugar, el estudio revela resultados prometedores para el problema de datación estelar. Un error de $<0.5$ Gyr se puede considerar como un gran avance en el campo.

Por último, destacar que este trabajo ha servido de apoyo para la publicación de un artículo para el \emph{1st Workshop on AI for Space}. El artículo \citep{AI4STARTS} , titulado \emph{AI for dating stars: a benchmarking study for gyrochronology}, se basa en la aplicación de modelos regresivos de aprendizaje automático para reemplazar las combinaciones lineales que se utilizan en el campo de la estimación de edades estelares. Los modelos de IA empleados y la forma de compararlos siguen el guión expuesto en el Capítulo \ref{chap:AI_4_date} donde se realiza un \emph{benchmarking} de los escenarios vistos en la Sección \ref{sec:benchmark} con los modelos detallados en la Sección \ref{sec:models}. Las conclusiones a las que se llegan en el artículo son idénticas a las obtenidas en este proyecto.

%TODO_DONE: pon un párrafo aquí que diga que has publicado un trabajo con todo esto, dando todos los detalles.

\section{Meta-Learning aplicado al problema de la estimación de la edad de las estrellas}

En la segunda parte del trabajo, se estudia el algoritmo MAML (Meta-Agnostic Meta-Learning) para resolver el problema de la regresión de las edades estelares en un planteamiento típico de meta-learning, o aprender a aprender con pocas muestras. Sobre este problema, se obtienen diferentes resultados asociados a diferentes arquitecturas desarrolladas para el modelo. Los peores resultados van asociados a la arquitectura más simple probada, con una sola capa oculta y 40 células,  que muestra un MSE = 1.20 en su última actualización de gradiente. En contraposición, los mejores resultados se puede observar en el modelo que cuenta con 3 capas ocultas de 20 unidades cada una, con un MSE = 0.01. 
Es importante destacar que las configuraciones más complejas consiguen resultados de MSE muy próximos a cero en la última actualización de gradiente.
En cualquier caso, lo más relevante es que es la primera vez que se prueba una aproximación basada en meta-learning para abordar el problema de la datación estelar, y los resultados obtenidos son muy prometedores.

Respecto a la comparación de estos resultados con los obtenidos en el \emph{benchmarking} anterior, resulta inviable realizar una comparación directa debido a la métrica empleada para la función de pérdidas. Durante el primer experimento con los modelo clásicos se ha empleado el error medio absoluto, mientras que en este análisis se utiliza el error cuadrático medio. Es por esto que, como próximos pasos, sería interesante realizar un estudio sobre otros modelo y algoritmos que ofrezcan resultados comparables.

Tras lo comentado, se establecen como próximos pasos a seguir el análisis de otros algoritmos enfocados en el aprendizaje del modelo mediante un número reducido de muestras. Reptile \cite{nichol2018firstorder} es uno de estos algoritmos, matemáticamente es similar al algoritmo MAML estudiado en este proyecto ya que muestrea recursivamente una tarea, realizando un descenso de gradiente y actualizando los parámetros iniciales. Aún así, resultaría interesante una comparación de los rendimientos de ambos algoritmos. Otro estudio a tener en cuenta es el desarrollado en \cite{yao2021metalearning}, en este caso el algoritmo se denomina MLTI (Meta-Learning Task Interpolation). En este análisis se generan tareas adicionales tras muestrear aleatoriamente un par de tareas e interpolar características y sus correspondientes etiquetas.
 

\section{Conclusiones personales}

Como reflexión personal, considero que el desarrollo de este proyecto me ha permitido adquirir conocimientos generales y específicos sobre el mundo de la inteligencia artificial y la datación de estrellas. Hasta el momento en el que empecé el TFM, no sabía absolutamente nada de las técnicas de datación estelar ni de su importancia para la evolución del ser humano y de la ciencia. Gracias a la transferencia de conocimiento por parte de Andrés y Roberto en estos campos, he podido aprender lo requerido para enfrentarme a este proyecto. Esto me ha permitido alcanzar dos importantes hitos para: 1) obtener unos resultados lo suficientemente satisfactorios como para poder catalogarse como prometedores dentro del ámbito de la datación estelar y 2) aportar mi granito de arena en la elaboración de un artículo \cite{AI4STARTS} basado, en parte, en este TFM y publicado en el \emph{1st Workshop on AI for Space, CVPR, 2021}. Todo el código para reproducir los resultados del artículo lo hemos liberado públiamente \footnote{El código está idsponible en el siguiente repositorio: \url{https://github.com/gramuah/ai4datingstars}}.  %TODO_DONE: añadir enlace a la web, y citar nuestro trabajo en la bibliogrfía.. 

Por otro lado, este proyecto también me ha ayudado a conocer un poco mejor la dinámica que podría seguirse en un proyecto de investigación. Acostumbrado al mundo de la empresa privada en el que todo se hace deprisa y con una calidad cuestionable, el tener que dedicarle horas a leer artículos y probar líneas de código distintas me permite adquirir nuevas competencias.

%También considero que el papel de la figura de Director de TFM es crucial para obtener resultados satisfactorios, y es por eso que le agradezco a Roberto toda la ayuda y la orientación aportada para llegar a buen puerto en estre trabajo.
%TODO: Gracias a ti Jarmi. Esto lo dejamos fuera de la memoria, pues para eso está la sección de agradecimientos.





















